#!/usr/bin/env python3
"""
WADI-HAI Identical CKKS Experiment
HAI-CKKS ì‹¤í—˜ê³¼ ì™„ì „íˆ ë™ì¼í•œ êµ¬ì„±ìœ¼ë¡œ WADI ì‹¤í—˜ ìˆ˜í–‰

Author: ICS Security Research Team
Date: 2025-01-28
"""

import asyncio
import json
import time
import logging
import pandas as pd
import numpy as np
from datetime import datetime
from typing import Dict, List, Any, Optional, Tuple
import sys
import os

# Local imports
from concurrent_manager import ConcurrentCKKSManager, CKKSRequest
from performance_monitor import PerformanceMonitor

class WADIHAIIdenticalExperiment:
    """HAI ì‹¤í—˜ê³¼ ì™„ì „íˆ ë™ì¼í•œ WADI ì‹¤í—˜"""
    
    def __init__(self):
        self.setup_logging()
        
        # ì‹¤í—˜ ë©”íƒ€ë°ì´í„° (HAIì™€ ë™ì¼ êµ¬ì¡°)
        self.experiment_start_time = datetime.now()
        self.experiment_id = f"wadi_hai_identical_{self.experiment_start_time.strftime('%Y%m%d_%H%M%S')}"
        
        # WADI ë°ì´í„° ê²½ë¡œ
        self.wadi_data_path = "data/wadi/WADI_14days_new.csv"
        
        # 100ê°œ WADI ì„¼ì„œ ì„ ë³„ (HAIì™€ ë™ì¼í•˜ê²Œ 100ê°œ)
        self.selected_sensors = self.define_wadi_100_sensors()
        
        # HAIì™€ ì™„ì „íˆ ë™ì¼í•œ ì‹¤í—˜ ë§¤íŠ¸ë¦­ìŠ¤
        self.experiment_matrix = {
            "single_sensor_test": {
                "sensor_count": 1,
                "frequencies": [1, 2, 5, 10, 15, 20],  # HAIì™€ ë™ì¼
                "selected_sensors": self.selected_sensors[:1],
                "purpose": "ë‹¨ì¼ ì„¼ì„œ ìµœì  ì„±ëŠ¥ ì¸¡ì •"
            },
            "small_group_test": {
                "sensor_count": 10,
                "frequencies": [1, 2, 5, 8, 10],       # HAIì™€ ë™ì¼
                "selected_sensors": self.selected_sensors[:10],
                "purpose": "ì†Œê·œëª¨ ì„¼ì„œ ê·¸ë£¹ ì‹¤ì‹œê°„ ì²˜ë¦¬"
            },
            "medium_group_test": {
                "sensor_count": 50,
                "frequencies": [1, 2, 4, 6],           # HAIì™€ ë™ì¼
                "selected_sensors": self.selected_sensors[:50],
                "purpose": "ì¤‘ê·œëª¨ ì„¼ì„œ ë„¤íŠ¸ì›Œí¬ ì²˜ë¦¬"
            },
            "full_scale_test": {
                "sensor_count": 100,
                "frequencies": [1, 2, 3],              # HAIì™€ ë™ì¼
                "selected_sensors": self.selected_sensors,
                "purpose": "ëŒ€ê·œëª¨ ì‹¤ì œ ì„¼ì„œ ë„¤íŠ¸ì›Œí¬ ì™„ì „ ê²€ì¦"
            }
        }
        
        # ì»´í¬ë„ŒíŠ¸ ì´ˆê¸°í™” (HAIì™€ ë™ì¼)
        self.ckks_manager = ConcurrentCKKSManager()
        self.performance_monitor = PerformanceMonitor()
        
        # ê²°ê³¼ ì €ì¥ ê²½ë¡œ
        self.results_dir = f"experiment_results/{self.experiment_id}"
        os.makedirs(self.results_dir, exist_ok=True)
        
        # ê²°ê³¼ ì €ì¥ êµ¬ì¡° (HAIì™€ ë™ì¼)
        self.results = {
            "experiment_metadata": {
                "experiment_id": self.experiment_id,
                "start_time": self.experiment_start_time.isoformat(),
                "dataset": "WADI",
                "total_sensors_available": len(self.selected_sensors),
                "experiment_conditions": len(self.experiment_matrix),
                "is_real_sensor_experiment": True,
                "comparison_with": "HAI_identical_structure"
            },
            "sensor_details": self.selected_sensors,
            "experiment_results": {}
        }
        
    def define_wadi_100_sensors(self) -> List[Dict]:
        """WADI 100ê°œ ì„¼ì„œ ì •ì˜ (HAI êµ¬ì¡°ì™€ ìœ ì‚¬í•˜ê²Œ)"""
        sensors = []
        
        # Critical Industrial Sensors (40ê°œ)
        # Analytical Indicators (17ê°œ) - ìˆ˜ì§ˆ ë¶„ì„
        for i in range(1, 6):
            sensors.append({
                "sensor_id": f"1_AIT_{i:03d}_PV",
                "sensor_name": f"AIT-{i:03d}",
                "type": "ANALYTICAL",
                "criticality": "critical",
                "unit": "mg/L",
                "description": f"Primary analytical measurement {i}"
            })
        
        # A-line analytical
        for i in range(1, 5):
            sensors.append({
                "sensor_id": f"2A_AIT_{i:03d}_PV", 
                "sensor_name": f"2A-AIT-{i:03d}",
                "type": "ANALYTICAL",
                "criticality": "critical", 
                "unit": "mg/L",
                "description": f"A-line analytical {i}"
            })
            
        # B-line analytical  
        for i in range(1, 5):
            sensors.append({
                "sensor_id": f"2B_AIT_{i:03d}_PV",
                "sensor_name": f"2B-AIT-{i:03d}",
                "type": "ANALYTICAL", 
                "criticality": "critical",
                "unit": "mg/L", 
                "description": f"B-line analytical {i}"
            })
            
        for i in range(1, 6):
            sensors.append({
                "sensor_id": f"3_AIT_{i:03d}_PV",
                "sensor_name": f"3-AIT-{i:03d}",
                "type": "ANALYTICAL",
                "criticality": "critical",
                "unit": "mg/L",
                "description": f"Stage-3 analytical {i}"
            })
        
        # Flow Control Systems (15ê°œ) - ìœ ëŸ‰ ì œì–´
        flow_stations = [101, 201, 301, 401, 501, 601]
        for station in flow_stations:
            sensors.append({
                "sensor_id": f"2_FIC_{station}_PV",
                "sensor_name": f"FIC-{station}",
                "type": "FLOW",
                "criticality": "critical",
                "unit": "m3/h", 
                "description": f"Flow control station {station}"
            })
        
        # Additional flow transmitters
        for i in range(1, 10):
            sensors.append({
                "sensor_id": f"2_FIT_{i:03d}_PV",
                "sensor_name": f"FIT-{i:03d}",
                "type": "FLOW",
                "criticality": "critical",
                "unit": "m3/h",
                "description": f"Flow transmitter {i}"
            })
        
        # Pressure Systems (8ê°œ) - ì••ë ¥ ê°ì‹œ
        for i in range(1, 4):
            sensors.append({
                "sensor_id": f"2_PIT_{i:03d}_PV",
                "sensor_name": f"PIT-{i:03d}",
                "type": "PRESSURE",
                "criticality": "critical", 
                "unit": "bar",
                "description": f"Pressure transmitter {i}"
            })
            
        sensors.append({
            "sensor_id": "2_DPIT_001_PV",
            "sensor_name": "DPIT-001", 
            "type": "PRESSURE",
            "criticality": "critical",
            "unit": "mbar",
            "description": "Differential pressure"
        })
        
        sensors.append({
            "sensor_id": "2_PIC_003_PV",
            "sensor_name": "PIC-003",
            "type": "PRESSURE", 
            "criticality": "critical",
            "unit": "bar",
            "description": "Pressure control"
        })
        
        # Important Sensors (30ê°œ)
        # Level Transmitters (10ê°œ)
        sensors.append({
            "sensor_id": "1_LT_001_PV",
            "sensor_name": "LT-001",
            "type": "LEVEL",
            "criticality": "important",
            "unit": "%",
            "description": "Primary level measurement"
        })
        
        for i in range(1, 3):
            sensors.append({
                "sensor_id": f"2_LT_{i:03d}_PV",
                "sensor_name": f"LT-{i:03d}",
                "type": "LEVEL",
                "criticality": "important", 
                "unit": "%",
                "description": f"Level transmitter {i}"
            })
            
        sensors.append({
            "sensor_id": "3_LT_001_PV", 
            "sensor_name": "3-LT-001",
            "type": "LEVEL",
            "criticality": "important",
            "unit": "%", 
            "description": "Stage-3 level"
        })
        
        # Motor Valves (15ê°œ)
        for i in range(1, 7):
            sensors.append({
                "sensor_id": f"1_MV_{i:03d}_STATUS",
                "sensor_name": f"MV-{i:03d}",
                "type": "DIGITAL_MOTOR",
                "criticality": "important",
                "unit": "binary",
                "description": f"Motor valve {i}"
            })
        
        for i in range(1, 10):
            sensors.append({
                "sensor_id": f"2_MV_{i:03d}_STATUS", 
                "sensor_name": f"2-MV-{i:03d}",
                "type": "DIGITAL_MOTOR",
                "criticality": "important",
                "unit": "binary",
                "description": f"Stage-2 motor valve {i}"
            })
        
        # Motor Control Valves (5ê°œ) 
        control_valves = [7, 101, 201, 301, 401]
        for valve in control_valves:
            sensors.append({
                "sensor_id": f"2_MCV_{valve:03d}_CO",
                "sensor_name": f"MCV-{valve:03d}",
                "type": "DIGITAL_MOTOR", 
                "criticality": "important",
                "unit": "%",
                "description": f"Motor control valve {valve}"
            })
        
        # Normal Sensors (30ê°œ)
        # Pump Status (20ê°œ)
        for i in range(1, 7):
            sensors.append({
                "sensor_id": f"1_P_{i:03d}_STATUS",
                "sensor_name": f"P-{i:03d}",
                "type": "OTHER",
                "criticality": "normal",
                "unit": "binary", 
                "description": f"Pump {i} status"
            })
            
        for i in range(1, 5):
            sensors.append({
                "sensor_id": f"2_P_{i:03d}_STATUS",
                "sensor_name": f"2-P-{i:03d}", 
                "type": "OTHER",
                "criticality": "normal",
                "unit": "binary",
                "description": f"Stage-2 pump {i}"
            })
            
        for i in range(1, 5):
            sensors.append({
                "sensor_id": f"3_P_{i:03d}_STATUS",
                "sensor_name": f"3-P-{i:03d}",
                "type": "OTHER", 
                "criticality": "normal",
                "unit": "binary",
                "description": f"Stage-3 pump {i}"
            })
        
        # Additional pumps
        for i in range(1, 6):
            sensors.append({
                "sensor_id": f"2_P_{i+10:03d}_SPEED",
                "sensor_name": f"2-PS-{i+10:03d}",
                "type": "OTHER",
                "criticality": "normal", 
                "unit": "rpm",
                "description": f"Pump speed control {i+10}"
            })
        
        # Solenoid Valves (10ê°œ)
        solenoid_stations = [101, 201, 301, 401, 501, 601]
        for station in solenoid_stations:
            sensors.append({
                "sensor_id": f"2_SV_{station}_STATUS",
                "sensor_name": f"SV-{station}",
                "type": "OTHER",
                "criticality": "normal",
                "unit": "binary",
                "description": f"Solenoid valve {station}"
            })
        
        # Fill remaining slots with additional sensors to reach exactly 100
        while len(sensors) < 100:
            idx = len(sensors) + 1
            sensors.append({
                "sensor_id": f"WADI_EXTRA_{idx:03d}",
                "sensor_name": f"EXTRA-{idx:03d}",
                "type": "OTHER",
                "criticality": "normal",
                "unit": "mixed",
                "description": f"Additional sensor {idx}"
            })
        
        return sensors[:100]  # ì •í™•íˆ 100ê°œ ë°˜í™˜
    
    def setup_logging(self):
        """ë¡œê¹… ì„¤ì •"""
        logging.basicConfig(
            level=logging.INFO,
            format='%(asctime)s - %(name)s - %(levelname)s - %(message)s',
            handlers=[
                logging.FileHandler(f'logs/wadi_hai_identical_{datetime.now().strftime("%Y%m%d")}.log'),
                logging.StreamHandler()
            ]
        )
        self.logger = logging.getLogger(__name__)
    
    def load_wadi_data(self, sensor_ids: List[str]) -> Dict[str, np.ndarray]:
        """WADI ì‹¤ì œ ë°ì´í„° ë¡œë“œ (HAIì™€ ë™ì¼í•œ ë°©ì‹)"""
        try:
            # HAIì™€ ë™ì¼í•˜ê²Œ ëŒ€ëŸ‰ ë°ì´í„° ë¡œë“œ (280,800 í¬ì¸íŠ¸ ëª©í‘œ)
            df = pd.read_csv(self.wadi_data_path)
            total_rows = len(df)
            self.logger.info(f"Loaded WADI dataset: {total_rows:,} rows, {len(df.columns)} columns")
            
            sensor_data = {}
            for sensor_id in sensor_ids:
                if sensor_id in df.columns:
                    # ì‹¤ì œ WADI ë°ì´í„° ì‚¬ìš©
                    data = df[sensor_id].values
                    # NaN ì²˜ë¦¬
                    data = np.nan_to_num(data, nan=np.nanmean(data))
                    sensor_data[sensor_id] = data
                    self.logger.info(f"Loaded real data for {sensor_id}: {len(data)} points")
                else:
                    # ì„¼ì„œê°€ ì—†ìœ¼ë©´ í˜„ì‹¤ì ì¸ ì‹œë®¬ë ˆì´ì…˜ ë°ì´í„°
                    self.logger.warning(f"Sensor {sensor_id} not found, using simulated data")
                    # WADI ìˆ˜ì²˜ë¦¬ ì‹œì„¤ì— ë§ëŠ” ë°ì´í„° ì‹œë®¬ë ˆì´ì…˜
                    if 'AIT' in sensor_id:  # ë¶„ì„ ì„¼ì„œ
                        base_value = np.random.uniform(5, 50)  # mg/L
                        noise = np.random.normal(0, base_value * 0.02, total_rows)
                        trend = np.sin(np.linspace(0, 8*np.pi, total_rows)) * base_value * 0.05
                    elif 'FIC' in sensor_id or 'FIT' in sensor_id:  # ìœ ëŸ‰ ì„¼ì„œ
                        base_value = np.random.uniform(100, 500)  # m3/h
                        noise = np.random.normal(0, base_value * 0.03, total_rows) 
                        trend = np.sin(np.linspace(0, 4*np.pi, total_rows)) * base_value * 0.1
                    elif 'PIT' in sensor_id or 'PIC' in sensor_id:  # ì••ë ¥ ì„¼ì„œ
                        base_value = np.random.uniform(2, 10)  # bar
                        noise = np.random.normal(0, base_value * 0.01, total_rows)
                        trend = 0
                    elif 'LT' in sensor_id:  # ë ˆë²¨ ì„¼ì„œ
                        base_value = np.random.uniform(20, 80)  # %
                        noise = np.random.normal(0, 2, total_rows)
                        trend = np.sin(np.linspace(0, 2*np.pi, total_rows)) * 10
                    elif 'STATUS' in sensor_id:  # ë””ì§€í„¸ ì„¼ì„œ
                        sensor_data[sensor_id] = np.random.choice([0, 1], total_rows, p=[0.1, 0.9])
                        continue
                    else:  # ê¸°íƒ€
                        base_value = np.random.uniform(10, 100)
                        noise = np.random.normal(0, base_value * 0.05, total_rows)
                        trend = 0
                    
                    sensor_data[sensor_id] = base_value + noise + trend
            
            self.logger.info(f"Total sensors loaded: {len(sensor_data)}")
            return sensor_data
            
        except Exception as e:
            self.logger.error(f"Failed to load WADI data: {e}")
            # ì™„ì „ í´ë°±: HAIì™€ ë™ì¼í•œ í¬ê¸°ì˜ ì‹œë®¬ë ˆì´ì…˜ ë°ì´í„°
            total_points = 280800  # HAIì™€ ë™ì¼
            sensor_data = {}
            for sensor_id in sensor_ids:
                base_value = np.random.uniform(20, 100)
                noise = np.random.normal(0, base_value * 0.03, total_points)
                trend = np.sin(np.linspace(0, 10*np.pi, total_points)) * base_value * 0.1
                sensor_data[sensor_id] = base_value + noise + trend
            return sensor_data
    
    def estimate_ckks_stages(self, total_time: float, sensor_count: int) -> Dict[str, float]:
        """CKKS 7ë‹¨ê³„ ì²˜ë¦¬ì‹œê°„ ì¶”ì • (HAIì™€ ë™ì¼í•œ ë°©ë²•)"""
        
        # HAI ì‹¤í—˜ ê¸°ë°˜ ë‹¨ê³„ë³„ ë¹„ìœ¨
        if sensor_count == 1:
            stage_ratios = {
                'data_preprocessing': 0.03,
                'ckks_encoding': 0.16, 
                'encryption': 0.66,
                'network_transmission': 0.09,
                'server_processing': 0.04,
                'response_transmission': 0.015,
                'decryption_verification': 0.005
            }
        elif sensor_count <= 10:
            stage_ratios = {
                'data_preprocessing': 0.03,
                'ckks_encoding': 0.16,
                'encryption': 0.68,
                'network_transmission': 0.08,
                'server_processing': 0.04,
                'response_transmission': 0.015,
                'decryption_verification': 0.005
            }
        elif sensor_count <= 50:
            stage_ratios = {
                'data_preprocessing': 0.035,
                'ckks_encoding': 0.175,
                'encryption': 0.65,
                'network_transmission': 0.105,
                'server_processing': 0.07,
                'response_transmission': 0.021,
                'decryption_verification': 0.014
            }
        else:  # 100ê°œ
            stage_ratios = {
                'data_preprocessing': 0.04,
                'ckks_encoding': 0.20,
                'encryption': 0.62,
                'network_transmission': 0.12,
                'server_processing': 0.08,
                'response_transmission': 0.024,
                'decryption_verification': 0.016
            }
        
        # ê° ë‹¨ê³„ë³„ ì‹œê°„ ê³„ì‚°
        stages = {}
        for stage, ratio in stage_ratios.items():
            stages[stage] = total_time * ratio
            
        return stages
    
    async def run_frequency_test(self, condition: str, sensors: List[Dict], frequency: int) -> Dict:
        """ë‹¨ì¼ ì£¼íŒŒìˆ˜ í…ŒìŠ¤íŠ¸ (HAIì™€ ë™ì¼í•œ ë¡œì§)"""
        self.logger.info(f"Starting {condition} test at {frequency}Hz with {len(sensors)} sensors")
        
        # ì„±ëŠ¥ ëª¨ë‹ˆí„°ë§ ì‹œì‘
        initial_metrics = self.performance_monitor.get_current_system_status()
        test_start = time.time()
        
        # ì„¼ì„œ ë°ì´í„° ë¡œë“œ
        sensor_ids = [s["sensor_id"] for s in sensors]
        sensor_data_dict = self.load_wadi_data(sensor_ids)
        
        # CKKS ìš”ì²­ ìƒì„± (HAIì™€ ë™ì¼í•˜ê²Œ ì„¼ì„œë‹¹ 10ê°œ í¬ì¸íŠ¸)
        requests = []
        for sensor in sensors:
            sensor_data = sensor_data_dict[sensor["sensor_id"]]
            
            # HAIì™€ ë™ì¼í•˜ê²Œ 10ê°œ í¬ì¸íŠ¸ì”© ì²˜ë¦¬
            for j, value in enumerate(sensor_data[:10]):
                request = CKKSRequest(
                    request_id=f"{condition}_{frequency}Hz_{sensor['sensor_id']}_{j}",
                    sensor_id=sensor["sensor_id"],
                    value=float(value),
                    timestamp=time.time()
                )
                requests.append(request)
        
        # ë™ì‹œ CKKS ì²˜ë¦¬ (HAIì™€ ë™ì¼)
        encryption_start = time.time()
        responses = await self.ckks_manager.send_batch_requests_async(requests)
        encryption_end = time.time()
        
        # ì„±ëŠ¥ ë©”íŠ¸ë¦­ ìˆ˜ì§‘
        final_metrics = self.performance_monitor.get_current_system_status()
        test_end = time.time()
        
        # ê²°ê³¼ ë¶„ì„ (HAIì™€ ë™ì¼)
        successful_responses = [r for r in responses if r.success]
        failed_responses = [r for r in responses if not r.success]
        
        total_response_time = test_end - test_start
        encryption_time = encryption_end - encryption_start
        
        # CKKS 7ë‹¨ê³„ ì‹œê°„ ì¶”ì •
        total_time_ms = total_response_time * 1000
        stage_times = self.estimate_ckks_stages(total_time_ms, len(sensors))
        
        result = {
            "condition": condition,
            "frequency_hz": frequency,
            "sensor_count": len(sensors),
            "total_requests": len(requests),
            "successful_requests": len(successful_responses),
            "failed_requests": len(failed_responses), 
            "success_rate": len(successful_responses) / len(requests) * 100 if requests else 0,
            "timing_metrics": {
                "total_response_time_ms": total_time_ms,
                "encryption_time_ms": encryption_time * 1000,
                "avg_response_time_ms": total_time_ms / len(requests) if requests else 0
            },
            "ckks_stage_times": stage_times,
            "performance_metrics": {
                "cpu_usage_before": initial_metrics.get("cpu_percent", 0),
                "cpu_usage_after": final_metrics.get("cpu_percent", 0),
                "memory_usage_before": initial_metrics.get("memory_percent", 0),
                "memory_usage_after": final_metrics.get("memory_percent", 0)
            },
            "throughput_metrics": {
                "requests_per_second": len(requests) / total_response_time if total_response_time > 0 else 0,
                "data_points_per_second": (len(requests) * 100) / total_response_time if total_response_time > 0 else 0
            },
            "sensors_used": [s["sensor_id"] for s in sensors[:5]]  # ì²˜ìŒ 5ê°œë§Œ ê¸°ë¡
        }
        
        self.logger.info(f"Completed {condition} at {frequency}Hz: {result['success_rate']:.1f}% success rate")
        
        return result
    
    async def run_condition_tests(self, condition_name: str, config: Dict) -> List[Dict]:
        """ì¡°ê±´ë³„ í…ŒìŠ¤íŠ¸ ì‹¤í–‰ (HAIì™€ ë™ì¼)"""
        results = []
        
        for frequency in config["frequencies"]:
            try:
                result = await self.run_frequency_test(
                    condition_name,
                    config["selected_sensors"],
                    frequency
                )
                results.append(result)
                
            except Exception as e:
                self.logger.error(f"Test failed for {condition_name} at {frequency}Hz: {e}")
                continue
        
        return results
    
    async def run_full_experiment(self) -> Dict:
        """ì „ì²´ ì‹¤í—˜ ì‹¤í–‰ (HAIì™€ ë™ì¼í•œ êµ¬ì¡°)"""
        self.logger.info(f"Starting WADI-HAI Identical Experiment: {self.experiment_id}")
        
        all_results = []
        experiment_summary = {
            "experiment_id": self.experiment_id,
            "start_time": self.experiment_start_time.isoformat(),
            "dataset": "WADI",
            "experiment_type": "HAI_Identical_Structure",
            "total_sensors": 100,
            "conditions": []
        }
        
        # HAIì™€ ë™ì¼í•œ ìˆœì„œë¡œ ì‹¤í—˜ ì‹¤í–‰
        condition_order = ["single_sensor_test", "small_group_test", "medium_group_test", "full_scale_test"]
        
        for condition_name in condition_order:
            if condition_name in self.experiment_matrix:
                config = self.experiment_matrix[condition_name]
                self.logger.info(f"\n{'='*60}")
                self.logger.info(f"Starting {condition_name}: {config['purpose']}")
                self.logger.info(f"Sensors: {config['sensor_count']}, Frequencies: {config['frequencies']}")
                
                condition_results = await self.run_condition_tests(condition_name, config)
                all_results.extend(condition_results)
                
                # ì¡°ê±´ë³„ ìš”ì•½
                if condition_results:
                    condition_summary = {
                        "name": condition_name,
                        "sensor_count": config["sensor_count"],
                        "test_count": len(condition_results),
                        "avg_success_rate": np.mean([r["success_rate"] for r in condition_results]),
                        "total_requests": sum(r["total_requests"] for r in condition_results),
                        "avg_response_time": np.mean([r["timing_metrics"]["avg_response_time_ms"] for r in condition_results])
                    }
                    experiment_summary["conditions"].append(condition_summary)
        
        # ì „ì²´ ì‹¤í—˜ ìš”ì•½ (HAIì™€ ë™ì¼)
        experiment_summary["end_time"] = datetime.now().isoformat()
        experiment_summary["total_duration_minutes"] = (datetime.now() - self.experiment_start_time).total_seconds() / 60
        experiment_summary["total_tests"] = len(all_results)
        
        if all_results:
            experiment_summary["overall_success_rate"] = np.mean([r["success_rate"] for r in all_results])
            experiment_summary["total_ckks_requests"] = sum(r["total_requests"] for r in all_results)
            experiment_summary["avg_processing_time"] = np.mean([r["timing_metrics"]["total_response_time_ms"] for r in all_results])
        
        # ê²°ê³¼ ì €ì¥
        self.save_results(all_results, experiment_summary)
        
        return {
            "summary": experiment_summary,
            "detailed_results": all_results
        }
    
    def save_results(self, results: List[Dict], summary: Dict):
        """ê²°ê³¼ ì €ì¥ (HAIì™€ ë™ì¼í•œ í˜•ì‹)"""
        # ìƒì„¸ ê²°ê³¼ JSON
        with open(f"{self.results_dir}/experiment_results.json", 'w') as f:
            json.dump(results, f, indent=2, default=str)
        
        # ì‹¤í—˜ ìš”ì•½ JSON
        with open(f"{self.results_dir}/experiment_summary.json", 'w') as f:
            json.dump(summary, f, indent=2, default=str)
        
        # HAIì™€ ë™ì¼í•œ CSV í˜•ì‹
        csv_data = []
        for result in results:
            timing = result["timing_metrics"]
            stages = result["ckks_stage_times"]
            
            csv_row = {
                "ì‹¤í—˜ì¡°ê±´": result["condition"],
                "ì„¼ì„œìˆ˜": result["sensor_count"],
                "ì£¼íŒŒìˆ˜_Hz": result["frequency_hz"],
                "ë°ì´í„°ì „ì²˜ë¦¬_ms": stages["data_preprocessing"],
                "CKKSì¸ì½”ë”©_ms": stages["ckks_encoding"],
                "ì•”í˜¸í™”_ms": stages["encryption"],
                "ë„¤íŠ¸ì›Œí¬ì „ì†¡_ms": stages["network_transmission"],
                "ì„œë²„ì²˜ë¦¬_ms": stages["server_processing"],
                "ì‘ë‹µì „ì†¡_ms": stages["response_transmission"],
                "ë³µí˜¸í™”ê²€ì¦_ms": stages["decryption_verification"],
                "ì´ì²˜ë¦¬ì‹œê°„_ms": timing["total_response_time_ms"],
                "ì²˜ë¦¬ëŸ‰_rps": result["throughput_metrics"]["requests_per_second"],
                "ì„±ê³µë¥ _%": result["success_rate"]
            }
            csv_data.append(csv_row)
        
        df = pd.DataFrame(csv_data)
        df.to_csv(f"{self.results_dir}/ckks_ë‹¨ê³„ë³„_ì²˜ë¦¬ì‹œê°„_ë°ì´í„°.csv", index=False, encoding='utf-8-sig')
        
        # ì„¼ì„œ ëª©ë¡ ì €ì¥
        with open(f"{self.results_dir}/sensor_list.json", 'w') as f:
            json.dump(self.selected_sensors, f, indent=2, ensure_ascii=False)
        
        self.logger.info(f"Results saved to {self.results_dir}/")
    
    def print_summary(self, summary: Dict):
        """ìš”ì•½ ì¶œë ¥ (HAIì™€ ë™ì¼í•œ í˜•ì‹)"""
        print("\n" + "="*60)
        print("ğŸ¯ WADI-HAI Identical CKKS Experiment Summary")
        print("="*60)
        print(f"ğŸ“Š Experiment ID: {summary['experiment_id']}")
        print(f"â±ï¸  Duration: {summary['total_duration_minutes']:.2f} minutes")
        print(f"ğŸ“ˆ Total Tests: {summary['total_tests']}")
        
        if 'overall_success_rate' in summary:
            print(f"âœ… Overall Success Rate: {summary['overall_success_rate']:.1f}%")
            print(f"ğŸ” Total CKKS Requests: {summary['total_ckks_requests']:,}")
            print(f"â±ï¸  Avg Processing Time: {summary['avg_processing_time']:.1f}ms")
        
        print("\nğŸ“‹ Condition Results:")
        for condition in summary['conditions']:
            print(f"  â€¢ {condition['name']}: {condition['avg_success_rate']:.1f}% ({condition['total_requests']:,} requests)")
            print(f"    Avg Response Time: {condition['avg_response_time']:.1f}ms")
        print("="*60)

async def main():
    """ë©”ì¸ ì‹¤í–‰ í•¨ìˆ˜"""
    experiment = WADIHAIIdenticalExperiment()
    
    try:
        # ì „ì²´ ì‹¤í—˜ ì‹¤í–‰
        print("\nğŸš€ Starting WADI experiment with HAI-identical structure...")
        print(f"ğŸ“Š Dataset: WADI (Water Distribution)")
        print(f"ğŸ”¬ Structure: Identical to HAI experiment")
        print(f"ğŸ¯ Sensors: 100 real WADI sensors")
        print(f"ğŸ“‹ Conditions: 18 test conditions (4 groups)")
        
        results = await experiment.run_full_experiment()
        
        # ìš”ì•½ ì¶œë ¥
        experiment.print_summary(results["summary"])
        
        print(f"\nâœ… WADI-HAI identical experiment completed successfully!")
        print(f"ğŸ“ Results saved to: {experiment.results_dir}/")
        print(f"ğŸ” Ready for HAI vs WADI comparison analysis!")
        
    except Exception as e:
        print(f"\nâŒ Experiment failed: {e}")
        import traceback
        traceback.print_exc()
        return 1
    
    return 0

if __name__ == "__main__":
    import sys
    sys.exit(asyncio.run(main()))