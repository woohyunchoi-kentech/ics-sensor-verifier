#!/usr/bin/env python3
"""
HAI-CKKS GPU ê°€ì† ì„±ëŠ¥ ì‹¤í—˜ ë©”ì¸ ìŠ¤í¬ë¦½íŠ¸
ì‹¤ì œ HAI ë°ì´í„°ì…‹ì„ ì‚¬ìš©í•œ ëŒ€ê·œëª¨ CKKS ì•”í˜¸í™” ì„±ëŠ¥ ì‹¤í—˜
"""

import asyncio
import json
import time
import logging
from pathlib import Path
from typing import Dict, List, Optional, Tuple
from datetime import datetime
import argparse
import sys

from hai_data_streamer import HAIDataStreamer, get_hai_sensor_list
from wadi_data_streamer import WADIDataStreamer, get_wadi_sensor_list
from performance_monitor import PerformanceMonitor
from concurrent_manager import ConcurrentCKKSManager, CKKSRequest
from safety_controller import SafetyController, SafetyLevel
from visualizer import ExperimentVisualizer

logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s',
    handlers=[
        logging.FileHandler('hai_ckks_experiment.log'),
        logging.StreamHandler()
    ]
)
logger = logging.getLogger(__name__)

class HAICKKSGPUExperiment:
    """HAI-CKKS GPU ê°€ì† ì„±ëŠ¥ ì‹¤í—˜ ë©”ì¸ í´ë˜ìŠ¤"""
    
    def __init__(self, 
                 csv_path: str,
                 server_host: str = "192.168.0.11",
                 server_port: int = 8085,
                 results_dir: str = "experiment_results"):
        """
        ì‹¤í—˜ í™˜ê²½ ì´ˆê¸°í™”
        
        Args:
            csv_path: HAI ë°ì´í„°ì…‹ CSV íŒŒì¼ ê²½ë¡œ
            server_host: CKKS ì„œë²„ í˜¸ìŠ¤íŠ¸
            server_port: CKKS ì„œë²„ í¬íŠ¸
            results_dir: ê²°ê³¼ ì €ì¥ ë””ë ‰í† ë¦¬
        """
        self.csv_path = Path(csv_path)
        self.server_host = server_host
        self.server_port = server_port
        self.results_dir = Path(results_dir)
        
        # ê²°ê³¼ ë””ë ‰í† ë¦¬ ìƒì„±
        self.results_dir.mkdir(exist_ok=True)
        
        # ì‹¤í—˜ ë§¤íŠ¸ë¦­ìŠ¤ ì •ì˜ (HMAC ë² ì´ìŠ¤ë¼ì¸ê³¼ ë™ì¼í•œ 16ì¡°ê±´)
        self.experiment_matrix = {
            1: [1, 2, 10, 100],      # 1ê°œ ì„¼ì„œ: 1, 2, 10, 100Hz
            10: [1, 2, 10, 100],     # 10ê°œ ì„¼ì„œ: 1, 2, 10, 100Hz  
            50: [1, 2, 10, 100],     # 50ê°œ ì„¼ì„œ: 1, 2, 10, 100Hz
            100: [1, 2, 10, 100]     # 100ê°œ ì„¼ì„œ: 1, 2, 10, 100Hz
        }
        
        # ì»´í¬ë„ŒíŠ¸ ì´ˆê¸°í™”
        self.performance_monitor = PerformanceMonitor()
        self.safety_controller = SafetyController()
        self.visualizer = ExperimentVisualizer()
        
        # ì‹¤í—˜ ìƒíƒœ
        self.current_experiment = None
        self.experiment_results = {}
        self.start_time = None
        
        logger.info(f"HAI-CKKS GPU ì‹¤í—˜ ì‹œìŠ¤í…œ ì´ˆê¸°í™” ì™„ë£Œ")
        logger.info(f"ë°ì´í„°ì…‹: {self.csv_path}")
        logger.info(f"ì„œë²„: {self.server_host}:{self.server_port}")
        logger.info(f"ê²°ê³¼ ë””ë ‰í† ë¦¬: {self.results_dir}")
    
    async def validate_server_connection(self) -> bool:
        """CKKS ì„œë²„ ì—°ê²° ê²€ì¦"""
        try:
            server_url = f"http://{self.server_host}:{self.server_port}"
            manager = ConcurrentCKKSManager(
                server_url=server_url,
                max_concurrent=1
            )
            
            # í…ŒìŠ¤íŠ¸ ìš”ì²­ ìƒì„±
            test_request = CKKSRequest(
                sensor_id="TEST-01",
                value=1.0,
                timestamp=time.time(),
                request_id="test_001"
            )
            
            # ë‹¨ì¼ ìš”ì²­ í…ŒìŠ¤íŠ¸
            response = await manager.send_single_request_async(test_request)
            
            if response.success:
                logger.info("âœ“ CKKS ì„œë²„ ì—°ê²° ì„±ê³µ")
                logger.info(f"  ì„œë²„ ì‘ë‹µì‹œê°„: {response.response_time_ms:.3f}ms")
                return True
            else:
                logger.error(f"âœ— CKKS ì„œë²„ ì—°ê²° ì‹¤íŒ¨: {response.error_message}")
                return False
                
        except Exception as e:
            logger.error(f"âœ— ì„œë²„ ì—°ê²° ê²€ì¦ ì‹¤íŒ¨: {e}")
            return False
    
    def prepare_sensor_data(self, sensor_count: int, dataset_type: str = "hai") -> List[str]:
        """ì‹¤í—˜ìš© ì„¼ì„œ ë°ì´í„° ì¤€ë¹„"""
        try:
            if dataset_type == "wadi":
                # WADI ë°ì´í„°ì…‹ì—ì„œ ì„¼ì„œ ì„ íƒ
                available_sensors = get_wadi_sensor_list(sensor_count)
            else:
                # HAI ë°ì´í„°ì…‹ì—ì„œ ì„¼ì„œ ì„ íƒ
                available_sensors = get_hai_sensor_list(str(self.csv_path), sensor_count)
            
            if len(available_sensors) < sensor_count:
                logger.warning(f"ìš”ì²­ëœ ì„¼ì„œ ìˆ˜ {sensor_count}ê°œë³´ë‹¤ ì ì€ {len(available_sensors)}ê°œë§Œ ì‚¬ìš© ê°€ëŠ¥")
                sensor_count = len(available_sensors)
            
            selected_sensors = available_sensors[:sensor_count]
            logger.info(f"{dataset_type.upper()} ì„ íƒëœ ì„¼ì„œ ({len(selected_sensors)}ê°œ): {selected_sensors[:3]}...")
            
            return selected_sensors
            
        except Exception as e:
            logger.error(f"ì„¼ì„œ ë°ì´í„° ì¤€ë¹„ ì‹¤íŒ¨: {e}")
            raise
    
    async def run_single_experiment(self, 
                                  sensor_count: int, 
                                  frequency_hz: float,
                                  duration_seconds: int = 60,
                                  target_requests: int = None,
                                  dataset_type: str = "hai") -> Dict:
        """ë‹¨ì¼ ì‹¤í—˜ ì‹¤í–‰"""
        
        experiment_id = f"{sensor_count}sensors_{frequency_hz}hz"
        if target_requests:
            logger.info(f"ğŸš€ ì‹¤í—˜ ì‹œì‘: {experiment_id} (ëª©í‘œ: {target_requests}ê°œ ìš”ì²­, ìµœëŒ€ {duration_seconds}ì´ˆ)")
        else:
            logger.info(f"ğŸš€ ì‹¤í—˜ ì‹œì‘: {experiment_id} ({duration_seconds}ì´ˆ)")
        
        self.current_experiment = {
            'id': experiment_id,
            'sensor_count': sensor_count,
            'frequency_hz': frequency_hz,
            'duration': duration_seconds,
            'start_time': time.time()
        }
        
        try:
            # 1. ì„¼ì„œ ë°ì´í„° ì¤€ë¹„
            sensors = self.prepare_sensor_data(sensor_count, dataset_type)
            
            # 2. ë°ì´í„° ìŠ¤íŠ¸ë¦¬ë¨¸ ìƒì„±
            if dataset_type == "wadi":
                streamer = WADIDataStreamer(
                    csv_path=str(self.csv_path),
                    sensor_list=sensors,
                    frequency_hz=frequency_hz
                )
            else:
                streamer = HAIDataStreamer(
                    csv_path=str(self.csv_path),
                    sensor_list=sensors,
                    frequency_hz=frequency_hz
                )
            
            # 3. CKKS ë§¤ë‹ˆì € ìƒì„± (ë™ì‹œì„± ì œí•œ)
            max_concurrent = min(sensor_count * 2, 50)  # ê³¼ë¶€í•˜ ë°©ì§€
            server_url = f"http://{self.server_host}:{self.server_port}"
            manager = ConcurrentCKKSManager(
                server_url=server_url,
                max_concurrent=max_concurrent
            )
            
            # 4. ì„±ëŠ¥ ëª¨ë‹ˆí„°ë§ ì‹œì‘
            self.performance_monitor.start_monitoring()
            
            # 5. ì‹¤í—˜ ë°ì´í„° ìˆ˜ì§‘
            experiment_data = {
                'metadata': self.current_experiment.copy(),
                'performance_samples': [],
                'system_samples': [],
                'ckks_metrics': [],
                'safety_events': []
            }
            
            # 6. ì‹¤ì‹œê°„ ë°ì´í„° ìŠ¤íŠ¸ë¦¬ë° ë° CKKS ì²˜ë¦¬
            experiment_start = time.time()
            sample_count = 0
            
            while time.time() - experiment_start < duration_seconds and (target_requests is None or sample_count < target_requests):
                cycle_start = time.time()
                
                # ì•ˆì „ì„± í™•ì¸
                is_safe, warnings = self.safety_controller.is_safe_to_continue()
                if not is_safe:
                    logger.error(f"âš ï¸ ì•ˆì „ì„± ë¬¸ì œë¡œ ì‹¤í—˜ ì¤‘ë‹¨: {warnings}")
                    experiment_data['safety_events'].append({
                        'timestamp': time.time(),
                        'event': 'experiment_stopped',
                        'reasons': warnings
                    })
                    break
                
                # HAI ë°ì´í„° ë°°ì¹˜ ê°€ì ¸ì˜¤ê¸°
                batch_data = streamer.get_sensor_batch(len(sensors))
                current_data = batch_data[0]
                
                # CKKS ìš”ì²­ ìƒì„±
                requests = []
                for i, (sensor_id, value) in enumerate(current_data['sensors'].items()):
                    request = CKKSRequest(
                        sensor_id=sensor_id,
                        value=value,
                        timestamp=current_data['timestamp'],
                        request_id=f"{sample_count}_{i}"
                    )
                    requests.append(request)
                
                # ë°°ì¹˜ CKKS ì²˜ë¦¬
                batch_start = time.time()
                responses = await manager.send_batch_requests_async(requests)
                batch_duration = time.time() - batch_start
                
                # ì„±ëŠ¥ ë©”íŠ¸ë¦­ ê¸°ë¡
                successful_responses = [r for r in responses if r.success]
                failed_responses = [r for r in responses if not r.success]
                
                if successful_responses:
                    avg_encryption_time = sum(r.encryption_time_ms for r in successful_responses if r.encryption_time_ms) / len(successful_responses)
                    # decryption_timeì€ CKKSResponseì— ì—†ìœ¼ë¯€ë¡œ 0ìœ¼ë¡œ ì„¤ì •
                    avg_decryption_time = 0
                    avg_response_time = sum(r.response_time_ms for r in successful_responses) / len(successful_responses)
                    
                    self.performance_monitor.record_ckks_metric(
                        encryption_time=avg_encryption_time,
                        decryption_time=avg_decryption_time,
                        response_time=avg_response_time
                    )
                
                # ì‹¤í—˜ ë°ì´í„° ê¸°ë¡
                sample_data = {
                    'timestamp': time.time(),
                    'sample_id': sample_count,
                    'sensor_count': len(requests),
                    'successful_requests': len(successful_responses),
                    'failed_requests': len(failed_responses),
                    'batch_duration': batch_duration,
                    'cycle_duration': time.time() - cycle_start
                }
                experiment_data['performance_samples'].append(sample_data)
                
                # ì‹œìŠ¤í…œ ë©”íŠ¸ë¦­ ê¸°ë¡ (5ì´ˆë§ˆë‹¤)
                if sample_count % (frequency_hz * 5) == 0:
                    system_metrics = self.performance_monitor.get_current_system_status()
                    experiment_data['system_samples'].append({
                        'timestamp': time.time(),
                        'metrics': system_metrics
                    })
                
                # ì•ˆì „ì„± í™•ì¸ (ê°„ë‹¨í•œ ì²´í¬)
                current_status = self.performance_monitor.get_current_system_status()
                cpu_usage = current_status.get('cpu_percent', 0)
                memory_usage = current_status.get('memory_percent', 0)
                
                # ë†’ì€ ë¶€í•˜ ì‹œ ê²½ê³  ë¡œê·¸
                if cpu_usage > 80:
                    logger.warning(f"ë†’ì€ CPU ì‚¬ìš©ë¥ : {cpu_usage:.1f}%")
                if memory_usage > 80:
                    logger.warning(f"ë†’ì€ ë©”ëª¨ë¦¬ ì‚¬ìš©ë¥ : {memory_usage:.1f}%")
                
                sample_count += 1
                
                # ì£¼ê¸° ì¡°ì ˆ
                cycle_duration = time.time() - cycle_start
                target_interval = 1.0 / frequency_hz
                sleep_time = max(0, target_interval - cycle_duration)
                
                if sleep_time > 0:
                    await asyncio.sleep(sleep_time)
                elif cycle_duration > target_interval * 1.5:
                    logger.warning(f"ì£¼ê¸° ì§€ì—°: {cycle_duration:.3f}s (ëª©í‘œ: {target_interval:.3f}s)")
            
            # 7. ì‹¤í—˜ ì¢…ë£Œ ë° ê²°ê³¼ ì •ë¦¬
            experiment_duration = time.time() - experiment_start
            experiment_data['metadata']['actual_duration'] = experiment_duration
            experiment_data['metadata']['total_samples'] = sample_count
            
            # CKKS ë©”íŠ¸ë¦­ ìˆ˜ì§‘
            ckks_metrics = self.performance_monitor.get_ckks_statistics()
            experiment_data['ckks_metrics'] = ckks_metrics
            
            logger.info(f"âœ… ì‹¤í—˜ ì™„ë£Œ: {experiment_id}")
            logger.info(f"   ì‹¤í–‰ ì‹œê°„: {experiment_duration:.1f}ì´ˆ")
            logger.info(f"   ì´ ìƒ˜í”Œ: {sample_count}ê°œ")
            logger.info(f"   í‰ê·  ì‘ë‹µì‹œê°„: {ckks_metrics.get('avg_response_time', 0):.3f}ms")
            
            return experiment_data
            
        except Exception as e:
            logger.error(f"âŒ ì‹¤í—˜ ì‹¤í–‰ ì¤‘ ì˜¤ë¥˜: {e}")
            raise
        
        finally:
            # ì„±ëŠ¥ ëª¨ë‹ˆí„°ë§ ì •ì§€
            self.performance_monitor.stop_monitoring()
            self.current_experiment = None
    
    async def run_full_experiment_matrix(self) -> Dict:
        """ì „ì²´ ì‹¤í—˜ ë§¤íŠ¸ë¦­ìŠ¤ ì‹¤í–‰"""
        
        logger.info("ğŸ¯ ì „ì²´ ì‹¤í—˜ ë§¤íŠ¸ë¦­ìŠ¤ ì‹œì‘")
        logger.info(f"ì‹¤í—˜ ì¡°ê±´: {sum(len(freqs) for freqs in self.experiment_matrix.values())}ê°œ")
        
        self.start_time = time.time()
        all_results = {
            'experiment_info': {
                'start_time': self.start_time,
                'csv_path': str(self.csv_path),
                'server': f"{self.server_host}:{self.server_port}",
                'matrix': self.experiment_matrix
            },
            'results': {}
        }
        
        try:
            # ì„œë²„ ì—°ê²° ê²€ì¦
            if not await self.validate_server_connection():
                raise RuntimeError("CKKS ì„œë²„ ì—°ê²° ì‹¤íŒ¨")
            
            total_experiments = sum(len(freqs) for freqs in self.experiment_matrix.values())
            completed_experiments = 0
            
            # ê° ì„¼ì„œ ìˆ˜ë³„ë¡œ ì‹¤í—˜ ì‹¤í–‰
            for sensor_count, frequencies in self.experiment_matrix.items():
                logger.info(f"\nğŸ“Š {sensor_count}ê°œ ì„¼ì„œ ì‹¤í—˜ ì‹œì‘")
                
                sensor_results = {}
                
                for frequency_hz in frequencies:
                    try:
                        # ë‹¨ì¼ ì‹¤í—˜ ì‹¤í–‰ (1000ê°œ ìš”ì²­ ê¸°ì¤€)
                        target_requests = 1000
                        duration_seconds = max(30, target_requests // frequency_hz)
                        experiment_result = await self.run_single_experiment(
                            sensor_count=sensor_count,
                            frequency_hz=frequency_hz,
                            duration_seconds=duration_seconds,
                            target_requests=target_requests
                        )
                        
                        sensor_results[f"{frequency_hz}hz"] = experiment_result
                        completed_experiments += 1
                        
                        # ì§„í–‰ë¥  í‘œì‹œ
                        progress = (completed_experiments / total_experiments) * 100
                        logger.info(f"ğŸ“ˆ ì „ì²´ ì§„í–‰ë¥ : {progress:.1f}% ({completed_experiments}/{total_experiments})")
                        
                        # ì‹¤í—˜ ê°„ íœ´ì‹ ì‹œê°„ (ì„œë²„ ë¶€í•˜ ì™„í™”)
                        await asyncio.sleep(5)
                        
                    except Exception as e:
                        logger.error(f"âŒ ì‹¤í—˜ ì‹¤íŒ¨ ({sensor_count}ì„¼ì„œ, {frequency_hz}Hz): {e}")
                        sensor_results[f"{frequency_hz}hz"] = {
                            'error': str(e),
                            'timestamp': time.time()
                        }
                
                all_results['results'][f"{sensor_count}_sensors"] = sensor_results
                
                # ì„¼ì„œ ê·¸ë£¹ë³„ íœ´ì‹ ì‹œê°„
                logger.info(f"â¸ï¸ {sensor_count}ê°œ ì„¼ì„œ ì‹¤í—˜ ì™„ë£Œ, 10ì´ˆ ëŒ€ê¸°...")
                await asyncio.sleep(10)
            
            # ì‹¤í—˜ ì™„ë£Œ
            total_duration = time.time() - self.start_time
            all_results['experiment_info']['end_time'] = time.time()
            all_results['experiment_info']['total_duration'] = total_duration
            
            logger.info(f"\nğŸ‰ ì „ì²´ ì‹¤í—˜ ì™„ë£Œ!")
            logger.info(f"   ì´ ì‹¤í–‰ ì‹œê°„: {total_duration/60:.1f}ë¶„")
            logger.info(f"   ì™„ë£Œëœ ì‹¤í—˜: {completed_experiments}/{total_experiments}")
            
            return all_results
            
        except Exception as e:
            logger.error(f"âŒ ì‹¤í—˜ ë§¤íŠ¸ë¦­ìŠ¤ ì‹¤í–‰ ì‹¤íŒ¨: {e}")
            raise
    
    def save_results(self, results: Dict, filename_prefix: str = None) -> str:
        """ì‹¤í—˜ ê²°ê³¼ ì €ì¥"""
        
        if filename_prefix is None:
            timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
            filename_prefix = f"hai_ckks_experiment_{timestamp}"
        
        # JSON ê²°ê³¼ ì €ì¥
        json_path = self.results_dir / f"{filename_prefix}.json"
        
        with open(json_path, 'w', encoding='utf-8') as f:
            json.dump(results, f, indent=2, ensure_ascii=False, default=str)
        
        logger.info(f"ğŸ’¾ ì‹¤í—˜ ê²°ê³¼ ì €ì¥: {json_path}")
        return str(json_path)
    
    def generate_visualizations(self, results: Dict, output_prefix: str = None) -> List[str]:
        """ì‹¤í—˜ ê²°ê³¼ ì‹œê°í™” ìƒì„±"""
        
        if output_prefix is None:
            timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
            output_prefix = f"hai_ckks_viz_{timestamp}"
        
        visualization_files = []
        
        try:
            # ê° ì‹¤í—˜ë³„ ì‹œê°í™” ìƒì„±
            for sensor_key, sensor_results in results['results'].items():
                sensor_count = int(sensor_key.split('_')[0])
                
                for freq_key, experiment_data in sensor_results.items():
                    if 'error' in experiment_data:
                        continue
                    
                    frequency = float(freq_key.replace('hz', ''))
                    
                    # ì„±ëŠ¥ ì°¨íŠ¸ ìƒì„±
                    if experiment_data.get('performance_samples'):
                        chart_path = self.visualizer.create_realtime_performance_chart(
                            sensor_count=sensor_count,
                            performance_data=experiment_data['performance_samples'],
                            system_data=experiment_data.get('system_samples', [])
                        )
                        if chart_path:
                            visualization_files.append(chart_path)
            
            # ì¢…í•© ë¹„êµ ì°¨íŠ¸ ìƒì„±
            summary_path = self.visualizer.create_experiment_summary_chart(results)
            if summary_path:
                visualization_files.append(summary_path)
            
            logger.info(f"ğŸ“Š ì‹œê°í™” ìƒì„± ì™„ë£Œ: {len(visualization_files)}ê°œ íŒŒì¼")
            for file_path in visualization_files:
                logger.info(f"   ğŸ“ˆ {file_path}")
            
            return visualization_files
            
        except Exception as e:
            logger.error(f"ì‹œê°í™” ìƒì„± ì‹¤íŒ¨: {e}")
            return []

async def main():
    """ë©”ì¸ ì‹¤í–‰ í•¨ìˆ˜"""
    parser = argparse.ArgumentParser(description="HAI-CKKS GPU ê°€ì† ì„±ëŠ¥ ì‹¤í—˜")
    parser.add_argument("--csv", required=True, help="ë°ì´í„°ì…‹ CSV íŒŒì¼ ê²½ë¡œ")
    parser.add_argument("--dataset", choices=["hai", "wadi"], default="hai", help="ë°ì´í„°ì…‹ ìœ í˜• (hai ë˜ëŠ” wadi)")
    parser.add_argument("--host", default="192.168.0.11", help="CKKS ì„œë²„ í˜¸ìŠ¤íŠ¸")
    parser.add_argument("--port", type=int, default=8085, help="CKKS ì„œë²„ í¬íŠ¸")
    parser.add_argument("--results", default="experiment_results", help="ê²°ê³¼ ì €ì¥ ë””ë ‰í† ë¦¬")
    parser.add_argument("--test-connection", action="store_true", help="ì„œë²„ ì—°ê²° í…ŒìŠ¤íŠ¸ë§Œ ì‹¤í–‰")
    
    args = parser.parse_args()
    
    # HAI CSV íŒŒì¼ ì¡´ì¬ í™•ì¸
    if not Path(args.csv).exists():
        logger.error(f"HAI ë°ì´í„°ì…‹ íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {args.csv}")
        sys.exit(1)
    
    try:
        # ì‹¤í—˜ ì‹œìŠ¤í…œ ìƒì„±
        experiment = HAICKKSGPUExperiment(
            csv_path=args.csv,
            server_host=args.host,
            server_port=args.port,
            results_dir=args.results
        )
        
        # ì„œë²„ ì—°ê²° í…ŒìŠ¤íŠ¸ë§Œ ì‹¤í–‰
        if args.test_connection:
            logger.info("ğŸ” ì„œë²„ ì—°ê²° í…ŒìŠ¤íŠ¸ ì‹¤í–‰...")
            if await experiment.validate_server_connection():
                logger.info("âœ… ì„œë²„ ì—°ê²° ì„±ê³µ!")
                sys.exit(0)
            else:
                logger.error("âŒ ì„œë²„ ì—°ê²° ì‹¤íŒ¨!")
                sys.exit(1)
        
        # ì „ì²´ ì‹¤í—˜ ì‹¤í–‰
        logger.info("ğŸš€ HAI-CKKS GPU ì‹¤í—˜ ì‹œì‘...")
        
        results = await experiment.run_full_experiment_matrix()
        
        # ê²°ê³¼ ì €ì¥
        result_file = experiment.save_results(results)
        
        # ì‹œê°í™” ìƒì„±
        visualization_files = experiment.generate_visualizations(results)
        
        logger.info("\nğŸ‰ ì‹¤í—˜ ì™„ë£Œ!")
        logger.info(f"ğŸ“ ê²°ê³¼ íŒŒì¼: {result_file}")
        logger.info(f"ğŸ“Š ì‹œê°í™” íŒŒì¼: {len(visualization_files)}ê°œ")
        
    except KeyboardInterrupt:
        logger.info("âŒ ì‚¬ìš©ìì— ì˜í•´ ì‹¤í—˜ ì¤‘ë‹¨ë¨")
        sys.exit(1)
    except Exception as e:
        logger.error(f"âŒ ì‹¤í—˜ ì‹¤í–‰ ì‹¤íŒ¨: {e}")
        sys.exit(1)

if __name__ == "__main__":
    asyncio.run(main())