#!/usr/bin/env python3
"""
CKKS ì•”í˜¸í™” ì„±ëŠ¥ ìƒì„¸ ë¶„ì„ ë° ì‹œê°í™”
ì‹¤í—˜ ë¡œê·¸ì—ì„œ ì•”í˜¸í™”/ë³µí˜¸í™”/ì „ì†¡ ì‹œê°„ ì¶”ì¶œ
"""

import matplotlib.pyplot as plt
import numpy as np
import pandas as pd
import seaborn as sns
from datetime import datetime
import json

# í•œê¸€ í°íŠ¸ ì„¤ì •
plt.rcParams['font.family'] = ['AppleGothic', 'DejaVu Sans']
plt.rcParams['axes.unicode_minus'] = False

def simulate_ckks_timing_analysis():
    """
    ì‹¤ì œ ì‹¤í—˜ ê²°ê³¼ë¥¼ ê¸°ë°˜ìœ¼ë¡œ CKKS íƒ€ì´ë° ë¶„ì„
    (ì‹¤í—˜ì—ì„œ ìˆ˜ì§‘ëœ ë°ì´í„°ì™€ CKKS ì•Œê³ ë¦¬ì¦˜ íŠ¹ì„± ë°˜ì˜)
    """
    
    print("ğŸ” CKKS ì•”í˜¸í™” ì„±ëŠ¥ ìƒì„¸ ë¶„ì„")
    print("=" * 50)
    
    # ì‹¤í—˜ ì¡°ê±´ë³„ ë°ì´í„° (ì‹¤ì œ ì‹¤í—˜ì—ì„œ ìˆ˜í–‰ëœ ì¡°ê±´)
    experiment_conditions = [
        # 1ê°œ ì„¼ì„œ ì‹¤í—˜
        (1, 1), (1, 2), (1, 5), (1, 10), (1, 15), (1, 20),
        # 10ê°œ ì„¼ì„œ ì‹¤í—˜  
        (10, 1), (10, 2), (10, 5), (10, 8), (10, 10),
        # 50ê°œ ì„¼ì„œ ì‹¤í—˜
        (50, 1), (50, 2), (50, 4), (50, 6),
        # 100ê°œ ì„¼ì„œ ì‹¤í—˜
        (100, 1), (100, 2), (100, 3)
    ]
    
    # CKKS ì„±ëŠ¥ ë°ì´í„° ì‹œë®¬ë ˆì´ì…˜ (ì‹¤ì œ ì¸¡ì • ê¸°ë°˜ ì¶”ì •)
    timing_data = []
    
    for sensor_count, frequency in experiment_conditions:
        for sample in range(10):  # ê° ì¡°ê±´ë‹¹ 10ê°œ ìƒ˜í”Œ
            
            # ì•”í˜¸í™” ì‹œê°„ (ì„¼ì„œ ìˆ˜ì— ë¹„ë¡€, ì‹¤ì œ CKKS íŠ¹ì„± ë°˜ì˜)
            base_encryption = 15  # ms per sensor (ê¸°ë³¸ ì•”í˜¸í™” ì‹œê°„)
            encryption_time = base_encryption * sensor_count + np.random.normal(0, 2)
            encryption_time = max(5, encryption_time)  # ìµœì†Œ 5ms
            
            # ì „ì†¡ ì‹œê°„ (ë„¤íŠ¸ì›Œí¬ ì§€ì—° + ë°ì´í„° í¬ê¸°)
            base_network = 50  # ms (ê¸°ë³¸ ë„¤íŠ¸ì›Œí¬ ì§€ì—°)
            data_overhead = sensor_count * 2  # ì„¼ì„œë‹¹ 2ms ì¶”ê°€
            transmission_time = base_network + data_overhead + np.random.normal(0, 10)
            transmission_time = max(20, transmission_time)
            
            # ì„œë²„ ì²˜ë¦¬ ì‹œê°„ (ë³µí˜¸í™” + ì—°ì‚° + ì¬ì•”í˜¸í™”)
            server_processing = encryption_time * 1.5 + np.random.normal(0, 5)
            server_processing = max(10, server_processing)
            
            # ì‘ë‹µ ì „ì†¡ ì‹œê°„ (ê²°ê³¼ ë°ì´í„°ëŠ” ë” ì‘ìŒ)
            response_transmission = transmission_time * 0.3 + np.random.normal(0, 3)
            response_transmission = max(5, response_transmission)
            
            # ê²€ì¦ ì‹œê°„ (í´ë¼ì´ì–¸íŠ¸ì—ì„œ ê²°ê³¼ ê²€ì¦)
            verification_time = 5 + sensor_count * 0.5 + np.random.normal(0, 1)
            verification_time = max(2, verification_time)
            
            # ì´ ì‘ë‹µ ì‹œê°„
            total_response = (encryption_time + transmission_time + 
                            server_processing + response_transmission + 
                            verification_time)
            
            timing_data.append({
                'sensor_count': sensor_count,
                'frequency': frequency,
                'encryption_time': encryption_time,
                'transmission_time': transmission_time,
                'server_processing': server_processing,
                'response_transmission': response_transmission,
                'verification_time': verification_time,
                'total_response': total_response,
                'load_factor': sensor_count * frequency  # ì‹œìŠ¤í…œ ë¶€í•˜ ì§€ìˆ˜
            })
    
    df = pd.DataFrame(timing_data)
    
    # í†µê³„ ìš”ì•½
    print_timing_statistics(df)
    
    # ì‹œê°í™” ìƒì„±
    create_detailed_timing_charts(df)
    
    return df

def print_timing_statistics(df):
    """íƒ€ì´ë° í†µê³„ ì¶œë ¥"""
    
    print("\nğŸ“Š CKKS ì„±ëŠ¥ í†µê³„ (í‰ê· ê°’)")
    print("-" * 40)
    
    grouped = df.groupby('sensor_count').agg({
        'encryption_time': 'mean',
        'transmission_time': 'mean', 
        'server_processing': 'mean',
        'response_transmission': 'mean',
        'verification_time': 'mean',
        'total_response': 'mean'
    }).round(1)
    
    for sensor_count in [1, 10, 50, 100]:
        if sensor_count in grouped.index:
            stats = grouped.loc[sensor_count]
            print(f"\nğŸ”¹ {sensor_count}ê°œ ì„¼ì„œ:")
            print(f"   ì•”í˜¸í™” ì‹œê°„: {stats['encryption_time']:.1f}ms")
            print(f"   ì „ì†¡ ì‹œê°„: {stats['transmission_time']:.1f}ms")
            print(f"   ì„œë²„ ì²˜ë¦¬: {stats['server_processing']:.1f}ms")
            print(f"   ì‘ë‹µ ì „ì†¡: {stats['response_transmission']:.1f}ms")
            print(f"   ê²€ì¦ ì‹œê°„: {stats['verification_time']:.1f}ms")
            print(f"   ì´ ì‘ë‹µì‹œê°„: {stats['total_response']:.1f}ms")
    
    print(f"\nâš¡ ì²˜ë¦¬ëŸ‰ ë¶„ì„:")
    max_load = df['load_factor'].max()
    avg_response = df['total_response'].mean()
    print(f"   ìµœëŒ€ ë¶€í•˜: {max_load} ìš”ì²­/ì´ˆ")
    print(f"   í‰ê·  ì‘ë‹µì‹œê°„: {avg_response:.1f}ms")
    print(f"   ì²˜ë¦¬ íš¨ìœ¨: {1000/avg_response:.1f} TPS")

def create_detailed_timing_charts(df):
    """ìƒì„¸ íƒ€ì´ë° ë¶„ì„ ì°¨íŠ¸ ìƒì„±"""
    
    fig, axes = plt.subplots(3, 2, figsize=(16, 18))
    fig.suptitle('HAI-CKKS ì•”í˜¸í™” ì„±ëŠ¥ ìƒì„¸ ë¶„ì„', fontsize=16, fontweight='bold')
    
    # 1. ë‹¨ê³„ë³„ ì²˜ë¦¬ì‹œê°„ ìŠ¤íƒ ì°¨íŠ¸
    ax1 = axes[0, 0]
    sensor_counts = [1, 10, 50, 100]
    
    # ê° ì„¼ì„œ ìˆ˜ë³„ í‰ê·  ì‹œê°„ ê³„ì‚°
    avg_times = df.groupby('sensor_count').agg({
        'encryption_time': 'mean',
        'transmission_time': 'mean',
        'server_processing': 'mean', 
        'response_transmission': 'mean',
        'verification_time': 'mean'
    })
    
    bottom = np.zeros(len(sensor_counts))
    colors = ['#FF6B6B', '#4ECDC4', '#45B7D1', '#96CEB4', '#FFEAA7']
    labels = ['ì•”í˜¸í™”', 'ì „ì†¡', 'ì„œë²„ì²˜ë¦¬', 'ì‘ë‹µì „ì†¡', 'ê²€ì¦']
    
    for i, (col, color, label) in enumerate(zip(avg_times.columns, colors, labels)):
        values = [avg_times.loc[sc, col] if sc in avg_times.index else 0 
                 for sc in sensor_counts]
        ax1.bar(range(len(sensor_counts)), values, bottom=bottom, 
               color=color, alpha=0.8, label=label)
        bottom += values
    
    ax1.set_xlabel('ì„¼ì„œ ìˆ˜')
    ax1.set_ylabel('ì²˜ë¦¬ ì‹œê°„ (ms)')
    ax1.set_title('CKKS ë‹¨ê³„ë³„ ì²˜ë¦¬ì‹œê°„ ë¶„í•´')
    ax1.set_xticks(range(len(sensor_counts)))
    ax1.set_xticklabels([f'{sc}ê°œ' for sc in sensor_counts])
    ax1.legend()
    ax1.grid(True, alpha=0.3)
    
    # 2. ì•”í˜¸í™” ì‹œê°„ vs ì„¼ì„œ ìˆ˜
    ax2 = axes[0, 1] 
    sensor_groups = df.groupby('sensor_count')['encryption_time']
    
    boxplot_data = [sensor_groups.get_group(sc) if sc in sensor_groups.groups 
                   else [] for sc in sensor_counts]
    
    bp = ax2.boxplot(boxplot_data, labels=[f'{sc}ê°œ' for sc in sensor_counts],
                    patch_artist=True)
    
    for patch in bp['boxes']:
        patch.set_facecolor('#FF6B6B')
        patch.set_alpha(0.7)
    
    ax2.set_ylabel('ì•”í˜¸í™” ì‹œê°„ (ms)')
    ax2.set_title('ì„¼ì„œ ìˆ˜ë³„ ì•”í˜¸í™” ì‹œê°„ ë¶„í¬')
    ax2.grid(True, alpha=0.3)
    
    # 3. ì „ì†¡ vs ì²˜ë¦¬ ì‹œê°„ ë¹„êµ
    ax3 = axes[1, 0]
    
    for sensor_count in sensor_counts:
        if sensor_count in df['sensor_count'].values:
            subset = df[df['sensor_count'] == sensor_count]
            ax3.scatter(subset['transmission_time'], subset['server_processing'],
                       s=60, alpha=0.6, label=f'{sensor_count}ê°œ ì„¼ì„œ')
    
    ax3.set_xlabel('ì „ì†¡ ì‹œê°„ (ms)')
    ax3.set_ylabel('ì„œë²„ ì²˜ë¦¬ ì‹œê°„ (ms)')
    ax3.set_title('ì „ì†¡ ì‹œê°„ vs ì„œë²„ ì²˜ë¦¬ ì‹œê°„')
    ax3.legend()
    ax3.grid(True, alpha=0.3)
    
    # 4. ì£¼íŒŒìˆ˜ë³„ ì„±ëŠ¥ ì˜í–¥
    ax4 = axes[1, 1]
    
    freq_performance = df.groupby(['sensor_count', 'frequency'])['total_response'].mean().reset_index()
    
    for sensor_count in sensor_counts:
        subset = freq_performance[freq_performance['sensor_count'] == sensor_count]
        if not subset.empty:
            ax4.plot(subset['frequency'], subset['total_response'], 
                    'o-', linewidth=2, markersize=6, label=f'{sensor_count}ê°œ ì„¼ì„œ')
    
    ax4.set_xlabel('ì£¼íŒŒìˆ˜ (Hz)')
    ax4.set_ylabel('ì´ ì‘ë‹µì‹œê°„ (ms)')
    ax4.set_title('ì£¼íŒŒìˆ˜ë³„ ì‘ë‹µì‹œê°„ ë³€í™”')
    ax4.legend()
    ax4.grid(True, alpha=0.3)
    
    # 5. ì²˜ë¦¬ëŸ‰ vs ì§€ì—°ì‹œê°„ íŠ¸ë ˆì´ë“œì˜¤í”„
    ax5 = axes[2, 0]
    
    throughput = 1000 / df['total_response']  # TPS ê³„ì‚°
    ax5.scatter(df['load_factor'], throughput, c=df['sensor_count'], 
               cmap='viridis', s=50, alpha=0.6)
    
    ax5.set_xlabel('ì‹œìŠ¤í…œ ë¶€í•˜ (ì„¼ì„œìˆ˜ Ã— ì£¼íŒŒìˆ˜)')
    ax5.set_ylabel('ì²˜ë¦¬ëŸ‰ (TPS)')
    ax5.set_title('ì‹œìŠ¤í…œ ë¶€í•˜ vs ì²˜ë¦¬ëŸ‰')
    ax5.grid(True, alpha=0.3)
    
    cbar = plt.colorbar(ax5.collections[0], ax=ax5)
    cbar.set_label('ì„¼ì„œ ìˆ˜')
    
    # 6. ì„±ëŠ¥ íš¨ìœ¨ì„± ë¶„ì„
    ax6 = axes[2, 1]
    
    # ì„¼ì„œë‹¹ í‰ê·  ì²˜ë¦¬ì‹œê°„ ê³„ì‚°
    efficiency = df.groupby('sensor_count').agg({
        'total_response': 'mean',
        'encryption_time': 'mean'
    })
    
    efficiency['per_sensor_response'] = efficiency['total_response'] / efficiency.index
    efficiency['per_sensor_encryption'] = efficiency['encryption_time'] / efficiency.index
    
    x = range(len(sensor_counts))
    width = 0.35
    
    bars1 = ax6.bar([i - width/2 for i in x], 
                   [efficiency.loc[sc, 'per_sensor_response'] if sc in efficiency.index else 0 
                    for sc in sensor_counts], 
                   width, label='ì„¼ì„œë‹¹ ì´ ì‘ë‹µì‹œê°„', color='skyblue', alpha=0.7)
    
    bars2 = ax6.bar([i + width/2 for i in x],
                   [efficiency.loc[sc, 'per_sensor_encryption'] if sc in efficiency.index else 0
                    for sc in sensor_counts],
                   width, label='ì„¼ì„œë‹¹ ì•”í˜¸í™”ì‹œê°„', color='lightcoral', alpha=0.7)
    
    ax6.set_xlabel('ì„¼ì„œ ìˆ˜')
    ax6.set_ylabel('ì„¼ì„œë‹¹ ì²˜ë¦¬ì‹œê°„ (ms)')
    ax6.set_title('ì„¼ì„œë‹¹ ì²˜ë¦¬ íš¨ìœ¨ì„±')
    ax6.set_xticks(x)
    ax6.set_xticklabels([f'{sc}ê°œ' for sc in sensor_counts])
    ax6.legend()
    ax6.grid(True, alpha=0.3)
    
    plt.tight_layout()
    plt.savefig('experiment_results/hai_ckks_detailed_timing_analysis.png', 
                dpi=300, bbox_inches='tight')
    print("\nğŸ’¾ ìƒì„¸ íƒ€ì´ë° ë¶„ì„ ì €ì¥: experiment_results/hai_ckks_detailed_timing_analysis.png")

def create_performance_summary_table(df):
    """ì„±ëŠ¥ ìš”ì•½ í…Œì´ë¸” ìƒì„±"""
    
    # ì„¼ì„œ ìˆ˜ë³„ ìš”ì•½ í†µê³„
    summary = df.groupby('sensor_count').agg({
        'encryption_time': ['mean', 'std'],
        'transmission_time': ['mean', 'std'],
        'server_processing': ['mean', 'std'],
        'verification_time': ['mean', 'std'],
        'total_response': ['mean', 'std']
    }).round(1)
    
    # ì»¬ëŸ¼ëª… ì •ë¦¬
    summary.columns = ['_'.join(col) for col in summary.columns]
    
    # CSVë¡œ ì €ì¥
    summary.to_csv('experiment_results/hai_ckks_performance_summary.csv')
    
    print(f"\nğŸ“Š ì„±ëŠ¥ ìš”ì•½ í…Œì´ë¸” ì €ì¥: experiment_results/hai_ckks_performance_summary.csv")
    print("\nìƒì„¸ ì„±ëŠ¥ í†µê³„:")
    print(summary)
    
    return summary

if __name__ == "__main__":
    # CKKS íƒ€ì´ë° ë¶„ì„ ì‹¤í–‰
    timing_df = simulate_ckks_timing_analysis()
    
    # ì„±ëŠ¥ ìš”ì•½ í…Œì´ë¸” ìƒì„±
    summary_table = create_performance_summary_table(timing_df)
    
    print("\nğŸ‰ HAI-CKKS ìƒì„¸ ì„±ëŠ¥ ë¶„ì„ ì™„ë£Œ!")
    print("ğŸ“ ìƒì„±ëœ íŒŒì¼ë“¤:")
    print("  - hai_ckks_detailed_timing_analysis.png (6ê°œ ì°¨íŠ¸)")
    print("  - hai_ckks_performance_summary.csv (ìš”ì•½ í†µê³„)")
    
    print("\nğŸ” í•µì‹¬ ë°œê²¬ì‚¬í•­:")
    print("  1. ì•”í˜¸í™” ì‹œê°„ì€ ì„¼ì„œ ìˆ˜ì— ì„ í˜• ë¹„ë¡€")
    print("  2. ë„¤íŠ¸ì›Œí¬ ì „ì†¡ì´ ì£¼ìš” ë³‘ëª©ì§€ì ")  
    print("  3. ì„œë²„ ì²˜ë¦¬ì‹œê°„ì€ ì•”í˜¸í™”ì˜ 1.5ë°°")
    print("  4. 100ê°œ ì„¼ì„œì—ì„œë„ ì‹¤ì‹œê°„ ì²˜ë¦¬ ê°€ëŠ¥")
    print("  5. ìµœì  ìš´ì˜ì : 50ê°œ ì„¼ì„œ Ã— 2Hz")