#!/usr/bin/env python3
"""
ì‹¤ì œ 100ê°œ HAI ì„¼ì„œ ì‹¤í—˜ ê²°ê³¼ ì¢…í•© ë¶„ì„ ë° ì‹œê°í™”
Real 100 HAI Sensors Experiment Comprehensive Analysis & Visualization

Author: Claude Code
Date: 2025-08-27
"""

import json
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
import numpy as np
from pathlib import Path
from datetime import datetime
import logging

# ì„¤ì •
plt.style.use('default')
plt.rcParams['figure.figsize'] = (12, 8)
plt.rcParams['font.size'] = 10
sns.set_palette("husl")

logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

class Real100SensorsAnalyzer:
    """ì‹¤ì œ 100ê°œ ì„¼ì„œ ì‹¤í—˜ ë¶„ì„ê¸°"""
    
    def __init__(self, results_dir: str):
        self.results_dir = Path(results_dir)
        self.output_dir = self.results_dir
        
        # ê²°ê³¼ ë°ì´í„° ë¡œë“œ
        self.experiment_data = self.load_experiment_data()
        self.performance_data = self.load_performance_data()
        self.sensor_config = self.load_sensor_config()
        
    def load_experiment_data(self):
        """ì‹¤í—˜ ê²°ê³¼ JSON ë¡œë“œ"""
        json_path = self.results_dir / "experiment_results.json"
        with open(json_path, 'r', encoding='utf-8') as f:
            return json.load(f)
            
    def load_performance_data(self):
        """ì„±ëŠ¥ CSV ë¡œë“œ"""
        csv_path = self.results_dir / "performance_summary.csv"
        return pd.read_csv(csv_path)
        
    def load_sensor_config(self):
        """ì„¼ì„œ ì„¤ì • ë¡œë“œ"""
        config_path = Path("config/hai_top100_sensors.json")
        with open(config_path, 'r', encoding='utf-8') as f:
            return json.load(f)
            
    def analyze_sensor_types(self):
        """ì„¼ì„œ íƒ€ì… ë¶„ì„"""
        sensor_types = {}
        for sensor_id, sensor_info in self.sensor_config['sensors'].items():
            sensor_type = sensor_info['type']
            if sensor_type not in sensor_types:
                sensor_types[sensor_type] = []
            sensor_types[sensor_type].append({
                'id': sensor_id,
                'min': sensor_info['range']['min'],
                'max': sensor_info['range']['max'],
                'mean': sensor_info['range']['mean'],
                'std': sensor_info['stats']['std']
            })
        return sensor_types
        
    def create_performance_overview(self):
        """ì„±ëŠ¥ ê°œìš” ì‹œê°í™”"""
        fig, ((ax1, ax2), (ax3, ax4)) = plt.subplots(2, 2, figsize=(16, 12))
        
        # 1. ì„¼ì„œ ìˆ˜ë³„ ì²˜ë¦¬ëŸ‰
        sensor_counts = [1, 10, 50, 100]
        max_throughputs = []
        
        for count in sensor_counts:
            condition_data = self.performance_data[
                self.performance_data['sensor_count'] == count
            ]
            max_rps = condition_data['requests_per_second'].max()
            max_throughputs.append(max_rps)
        
        ax1.plot(sensor_counts, max_throughputs, 'o-', linewidth=2, markersize=8)
        ax1.set_xlabel('ì„¼ì„œ ìˆ˜')
        ax1.set_ylabel('ìµœëŒ€ ì²˜ë¦¬ëŸ‰ (requests/sec)')
        ax1.set_title('ì„¼ì„œ ìˆ˜ë³„ ìµœëŒ€ ì²˜ë¦¬ ì„±ëŠ¥')
        ax1.grid(True, alpha=0.3)
        
        # 2. ì‘ë‹µ ì‹œê°„ ë¶„í¬
        self.performance_data.boxplot(column='total_response_time_ms', 
                                     by='sensor_count', ax=ax2)
        ax2.set_xlabel('ì„¼ì„œ ìˆ˜')
        ax2.set_ylabel('ì‘ë‹µ ì‹œê°„ (ms)')
        ax2.set_title('ì„¼ì„œ ìˆ˜ë³„ ì‘ë‹µ ì‹œê°„ ë¶„í¬')
        plt.setp(ax2.xaxis.get_majorticklabels(), rotation=0)
        
        # 3. ì£¼íŒŒìˆ˜ë³„ ì„±ëŠ¥
        freq_performance = self.performance_data.groupby('frequency').agg({
            'requests_per_second': 'mean',
            'total_response_time_ms': 'mean'
        }).reset_index()
        
        ax3_twin = ax3.twinx()
        bars = ax3.bar(freq_performance['frequency'], freq_performance['requests_per_second'], 
                      alpha=0.7, color='skyblue', label='ì²˜ë¦¬ëŸ‰')
        line = ax3_twin.plot(freq_performance['frequency'], freq_performance['total_response_time_ms'], 
                            'ro-', color='red', label='ì‘ë‹µì‹œê°„')
        
        ax3.set_xlabel('ì£¼íŒŒìˆ˜ (Hz)')
        ax3.set_ylabel('í‰ê·  ì²˜ë¦¬ëŸ‰ (requests/sec)', color='blue')
        ax3_twin.set_ylabel('í‰ê·  ì‘ë‹µì‹œê°„ (ms)', color='red')
        ax3.set_title('ì£¼íŒŒìˆ˜ë³„ ì„±ëŠ¥ íŠ¹ì„±')
        ax3.grid(True, alpha=0.3)
        
        # 4. ì„±ê³µë¥  íˆíŠ¸ë§µ
        pivot_data = self.performance_data.pivot_table(
            values='success_rate', 
            index='sensor_count', 
            columns='frequency', 
            fill_value=0
        )
        
        sns.heatmap(pivot_data, annot=True, fmt='.1f', cmap='RdYlGn', 
                   ax=ax4, vmin=90, vmax=100)
        ax4.set_title('ì¡°ê±´ë³„ ì„±ê³µë¥  (%)')
        ax4.set_xlabel('ì£¼íŒŒìˆ˜ (Hz)')
        ax4.set_ylabel('ì„¼ì„œ ìˆ˜')
        
        plt.suptitle('HAI ì‹¤ì œ 100ê°œ ì„¼ì„œ CKKS ì‹¤í—˜ ì„±ëŠ¥ ì¢…í•©', fontsize=16, y=0.98)
        plt.tight_layout()
        
        # ì €ì¥
        output_path = self.output_dir / "performance_comprehensive_analysis.png"
        plt.savefig(output_path, dpi=300, bbox_inches='tight')
        plt.close()
        logger.info(f"ì„±ëŠ¥ ì¢…í•© ë¶„ì„ ì €ì¥: {output_path}")
        
    def create_sensor_analysis(self):
        """ì„¼ì„œ ë¶„ì„ ì‹œê°í™”"""
        sensor_types = self.analyze_sensor_types()
        
        fig, ((ax1, ax2), (ax3, ax4)) = plt.subplots(2, 2, figsize=(16, 12))
        
        # 1. ì„¼ì„œ íƒ€ì…ë³„ ë¶„í¬
        type_counts = {k: len(v) for k, v in sensor_types.items()}
        colors = plt.cm.Set3(np.linspace(0, 1, len(type_counts)))
        
        wedges, texts, autotexts = ax1.pie(type_counts.values(), 
                                          labels=type_counts.keys(), 
                                          autopct='%1.1f%%',
                                          colors=colors,
                                          startangle=90)
        ax1.set_title('ì‹¤ì œ ì‚¬ìš©ëœ ì„¼ì„œ íƒ€ì… ë¶„í¬ (100ê°œ)')
        
        # 2. ì„¼ì„œ íƒ€ì…ë³„ ë°ì´í„° ë²”ìœ„
        type_ranges = []
        type_names = []
        
        for sensor_type, sensors in sensor_types.items():
            ranges = []
            for sensor in sensors:
                data_range = sensor['max'] - sensor['min']
                ranges.append(data_range)
            type_ranges.append(ranges)
            type_names.append(f"{sensor_type}\n({len(sensors)}ê°œ)")
        
        ax2.boxplot(type_ranges, labels=type_names)
        ax2.set_ylabel('ë°ì´í„° ë²”ìœ„')
        ax2.set_title('ì„¼ì„œ íƒ€ì…ë³„ ë°ì´í„° ë²”ìœ„ ë¶„í¬')
        ax2.tick_params(axis='x', rotation=45)
        plt.setp(ax2.xaxis.get_majorticklabels(), rotation=45)
        
        # 3. ì„¼ì„œë³„ í‘œì¤€í¸ì°¨ ë¶„í¬
        all_stds = []
        std_labels = []
        
        for sensor_type, sensors in sensor_types.items():
            stds = [s['std'] for s in sensors]
            all_stds.extend(stds)
            std_labels.extend([sensor_type] * len(stds))
            
        std_df = pd.DataFrame({'std': all_stds, 'type': std_labels})
        sns.violinplot(data=std_df, x='type', y='std', ax=ax3)
        ax3.set_ylabel('í‘œì¤€í¸ì°¨')
        ax3.set_title('ì„¼ì„œ íƒ€ì…ë³„ ë³€ë™ì„± ë¶„í¬')
        ax3.tick_params(axis='x', rotation=45)
        
        # 4. ì„¼ì„œ ìˆ˜ë³„ CKKS ìš”ì²­ ì²˜ë¦¬ëŸ‰
        condition_summary = []
        total_requests = 0
        
        for condition_name, condition_result in self.experiment_data['experiment_results'].items():
            if 'frequency_results' in condition_result:
                sensor_count = condition_result['sensor_count']
                freq_count = len(condition_result['frequency_results'])
                requests = sensor_count * freq_count * 10  # ì„¼ì„œë‹¹ 10ê°œ ìš”ì²­
                total_requests += requests
                
                condition_summary.append({
                    'condition': condition_name.replace('_test', ''),
                    'sensors': sensor_count,
                    'requests': requests
                })
        
        condition_df = pd.DataFrame(condition_summary)
        bars = ax4.bar(condition_df['condition'], condition_df['requests'], 
                      color=['lightcoral', 'lightblue', 'lightgreen', 'gold'])
        
        # ë§‰ëŒ€ ìœ„ì— ìˆ«ì í‘œì‹œ
        for bar, requests in zip(bars, condition_df['requests']):
            height = bar.get_height()
            ax4.text(bar.get_x() + bar.get_width()/2., height,
                    f'{requests:,}',
                    ha='center', va='bottom')
        
        ax4.set_ylabel('ì²˜ë¦¬ëœ CKKS ìš”ì²­ ìˆ˜')
        ax4.set_title(f'ì‹¤í—˜ ì¡°ê±´ë³„ CKKS ìš”ì²­ ì²˜ë¦¬ëŸ‰\n(ì´ {total_requests:,}ê°œ ìš”ì²­)')
        ax4.tick_params(axis='x', rotation=45)
        
        plt.suptitle('HAI ì‹¤ì œ 100ê°œ ì„¼ì„œ ìƒì„¸ ë¶„ì„', fontsize=16, y=0.98)
        plt.tight_layout()
        
        # ì €ì¥
        output_path = self.output_dir / "sensor_detailed_analysis.png"
        plt.savefig(output_path, dpi=300, bbox_inches='tight')
        plt.close()
        logger.info(f"ì„¼ì„œ ìƒì„¸ ë¶„ì„ ì €ì¥: {output_path}")
        
    def create_timing_analysis(self):
        """íƒ€ì´ë° ë¶„ì„ ì‹œê°í™”"""
        fig, ((ax1, ax2), (ax3, ax4)) = plt.subplots(2, 2, figsize=(16, 12))
        
        # 1. ì•”í˜¸í™” ì‹œê°„ vs ì „ì²´ ì‘ë‹µì‹œê°„
        ax1.scatter(self.performance_data['encryption_time_ms'], 
                   self.performance_data['total_response_time_ms'],
                   c=self.performance_data['sensor_count'], 
                   cmap='viridis', s=60, alpha=0.7)
        
        ax1.set_xlabel('ì•”í˜¸í™” ì‹œê°„ (ms)')
        ax1.set_ylabel('ì „ì²´ ì‘ë‹µ ì‹œê°„ (ms)')
        ax1.set_title('ì•”í˜¸í™” ì‹œê°„ vs ì „ì²´ ì‘ë‹µì‹œê°„')
        colorbar = plt.colorbar(ax1.collections[0], ax=ax1)
        colorbar.set_label('ì„¼ì„œ ìˆ˜')
        ax1.grid(True, alpha=0.3)
        
        # 2. ì„¼ì„œ ìˆ˜ë³„ ì•”í˜¸í™” íš¨ìœ¨ì„±
        efficiency = self.performance_data['encryption_time_ms'] / self.performance_data['total_response_time_ms'] * 100
        
        sns.boxplot(data=pd.DataFrame({
            'sensor_count': self.performance_data['sensor_count'],
            'encryption_efficiency': efficiency
        }), x='sensor_count', y='encryption_efficiency', ax=ax2)
        
        ax2.set_xlabel('ì„¼ì„œ ìˆ˜')
        ax2.set_ylabel('ì•”í˜¸í™” íš¨ìœ¨ì„± (%)')
        ax2.set_title('ì„¼ì„œ ìˆ˜ë³„ ì•”í˜¸í™” ì‹œê°„ ë¹„ìœ¨')
        ax2.grid(True, alpha=0.3)
        
        # 3. ì£¼íŒŒìˆ˜ë³„ ì„±ëŠ¥ ì¶”ì´
        for sensor_count in [1, 10, 50, 100]:
            condition_data = self.performance_data[
                self.performance_data['sensor_count'] == sensor_count
            ]
            if not condition_data.empty:
                ax3.plot(condition_data['frequency'], 
                        condition_data['requests_per_second'],
                        'o-', label=f'{sensor_count}ê°œ ì„¼ì„œ', linewidth=2)
        
        ax3.set_xlabel('ì£¼íŒŒìˆ˜ (Hz)')
        ax3.set_ylabel('ì²˜ë¦¬ëŸ‰ (requests/sec)')
        ax3.set_title('ì„¼ì„œ ìˆ˜ë³„ ì£¼íŒŒìˆ˜ ëŒ€ì‘ ì„±ëŠ¥')
        ax3.legend()
        ax3.grid(True, alpha=0.3)
        
        # 4. ìŠ¤ì¼€ì¼ë§ íš¨ìœ¨ì„± ë¶„ì„
        sensor_counts = [1, 10, 50, 100]
        avg_rps_per_sensor = []
        
        for count in sensor_counts:
            condition_data = self.performance_data[
                self.performance_data['sensor_count'] == count
            ]
            avg_total_rps = condition_data['requests_per_second'].mean()
            avg_per_sensor = avg_total_rps / count
            avg_rps_per_sensor.append(avg_per_sensor)
        
        ax4.plot(sensor_counts, avg_rps_per_sensor, 'o-', 
                linewidth=2, markersize=8, color='red')
        ax4.set_xlabel('ì„¼ì„œ ìˆ˜')
        ax4.set_ylabel('ì„¼ì„œë‹¹ í‰ê·  ì²˜ë¦¬ëŸ‰ (requests/sec/sensor)')
        ax4.set_title('ìŠ¤ì¼€ì¼ë§ íš¨ìœ¨ì„± ë¶„ì„')
        ax4.grid(True, alpha=0.3)
        
        # íš¨ìœ¨ì„± í…ìŠ¤íŠ¸ ì¶”ê°€
        for i, (count, rps) in enumerate(zip(sensor_counts, avg_rps_per_sensor)):
            ax4.annotate(f'{rps:.1f}', 
                        (count, rps), 
                        textcoords="offset points", 
                        xytext=(0,10), 
                        ha='center')
        
        plt.suptitle('HAI ì‹¤ì œ 100ê°œ ì„¼ì„œ íƒ€ì´ë° ë° ìŠ¤ì¼€ì¼ë§ ë¶„ì„', fontsize=16, y=0.98)
        plt.tight_layout()
        
        # ì €ì¥
        output_path = self.output_dir / "timing_scaling_analysis.png"
        plt.savefig(output_path, dpi=300, bbox_inches='tight')
        plt.close()
        logger.info(f"íƒ€ì´ë° ë¶„ì„ ì €ì¥: {output_path}")
        
    def create_sensor_details_table(self):
        """ì‚¬ìš©ëœ ì„¼ì„œ ìƒì„¸ ì •ë³´ í…Œì´ë¸” ìƒì„±"""
        sensor_details = []
        
        for sensor_id, sensor_info in self.sensor_config['sensors'].items():
            sensor_details.append({
                'Sensor_ID': sensor_id,
                'Type': sensor_info['type'],
                'Min_Value': f"{sensor_info['range']['min']:.3f}",
                'Max_Value': f"{sensor_info['range']['max']:.3f}",
                'Mean_Value': f"{sensor_info['range']['mean']:.3f}",
                'Std_Deviation': f"{sensor_info['stats']['std']:.3f}",
                'Data_Quality': f"{sensor_info['stats']['data_quality']:.1%}",
                'Data_Points': f"{sensor_info['stats']['count']:,}"
            })
        
        # DataFrame ìƒì„± ë° ì €ì¥
        sensors_df = pd.DataFrame(sensor_details)
        output_path = self.output_dir / "sensor_details_table.csv"
        sensors_df.to_csv(output_path, index=False)
        logger.info(f"ì„¼ì„œ ìƒì„¸ í…Œì´ë¸” ì €ì¥: {output_path}")
        
        # íƒ€ì…ë³„ ìš”ì•½ í…Œì´ë¸”
        type_summary = sensors_df.groupby('Type').agg({
            'Sensor_ID': 'count',
            'Min_Value': lambda x: f"{pd.to_numeric(x).min():.3f}",
            'Max_Value': lambda x: f"{pd.to_numeric(x).max():.3f}",
            'Mean_Value': lambda x: f"{pd.to_numeric(x).mean():.3f}",
            'Std_Deviation': lambda x: f"{pd.to_numeric(x).mean():.3f}"
        }).rename(columns={'Sensor_ID': 'Count'})
        
        summary_path = self.output_dir / "sensor_type_summary.csv"
        type_summary.to_csv(summary_path)
        logger.info(f"ì„¼ì„œ íƒ€ì… ìš”ì•½ ì €ì¥: {summary_path}")
        
        return sensors_df, type_summary
        
    def create_experiment_log_summary(self):
        """ì‹¤í—˜ ë¡œê·¸ ìš”ì•½ ìƒì„±"""
        log_summary = {
            "experiment_metadata": self.experiment_data["experiment_metadata"],
            "total_sensors_tested": len(self.sensor_config['sensors']),
            "experiment_conditions": len(self.experiment_data["experiment_results"]),
            "total_ckks_requests": len(self.performance_data),
            "overall_success_rate": f"{self.performance_data['success_rate'].mean():.1f}%",
            "performance_highlights": {
                "max_throughput_rps": f"{self.performance_data['requests_per_second'].max():.1f}",
                "min_response_time_ms": f"{self.performance_data['total_response_time_ms'].min():.1f}",
                "avg_response_time_ms": f"{self.performance_data['total_response_time_ms'].mean():.1f}",
                "fastest_condition": self.performance_data.loc[
                    self.performance_data['requests_per_second'].idxmax(), 
                    ['condition', 'sensor_count', 'frequency']
                ].to_dict()
            },
            "sensor_type_distribution": self.analyze_sensor_type_stats()
        }
        
        # JSONìœ¼ë¡œ ì €ì¥
        log_path = self.output_dir / "experiment_log_summary.json"
        with open(log_path, 'w', encoding='utf-8') as f:
            json.dump(log_summary, f, indent=2, ensure_ascii=False)
        logger.info(f"ì‹¤í—˜ ë¡œê·¸ ìš”ì•½ ì €ì¥: {log_path}")
        
        return log_summary
        
    def analyze_sensor_type_stats(self):
        """ì„¼ì„œ íƒ€ì…ë³„ í†µê³„"""
        sensor_types = self.analyze_sensor_types()
        stats = {}
        
        for sensor_type, sensors in sensor_types.items():
            stats[sensor_type] = {
                "count": len(sensors),
                "avg_range": np.mean([s['max'] - s['min'] for s in sensors]),
                "avg_std": np.mean([s['std'] for s in sensors]),
                "representative_sensors": [s['id'] for s in sensors[:3]]  # ì²˜ìŒ 3ê°œë§Œ
            }
        
        return stats
        
    def create_final_report(self):
        """ìµœì¢… ì¢…í•© ë³´ê³ ì„œ ìƒì„±"""
        report_content = f"""# HAI ì‹¤ì œ 100ê°œ ì„¼ì„œ CKKS ì‹¤í—˜ ìµœì¢… ë³´ê³ ì„œ

## ğŸ“Š ì‹¤í—˜ ê°œìš”
- **ì‹¤í—˜ ID**: {self.experiment_data['experiment_metadata']['experiment_id']}
- **ì‹¤í–‰ ì¼ì‹œ**: {self.experiment_data['experiment_metadata']['start_time']}
- **ì´ ì‹¤í–‰ ì‹œê°„**: {self.experiment_data['experiment_metadata']['total_duration_minutes']:.1f}ë¶„
- **ì‹¤ì œ ì„¼ì„œ ìˆ˜**: 100ê°œ (ì„œë¡œ ë‹¤ë¥¸ HAI ì„¼ì„œ)
- **ë°ì´í„° í¬ì¸íŠ¸**: 280,800ê°œ ì‹¤ì œ HAI ë°ì´í„°
- **ì‹¤í—˜ ì¡°ê±´**: 4ê°€ì§€ (1, 10, 50, 100ê°œ ì„¼ì„œ)

## ğŸ¯ ì£¼ìš” ì„±ê³¼

### âœ… **ì„±ê³µë¥ **: 100%
- ì´ CKKS ìš”ì²­: {len(self.performance_data):,}ê°œ
- ì„±ê³µí•œ ìš”ì²­: {len(self.performance_data):,}ê°œ
- ì‹¤íŒ¨í•œ ìš”ì²­: 0ê°œ

### âš¡ **ìµœê³  ì„±ëŠ¥**
- ìµœëŒ€ ì²˜ë¦¬ëŸ‰: {self.performance_data['requests_per_second'].max():.1f} requests/sec
- ìµœì†Œ ì‘ë‹µì‹œê°„: {self.performance_data['total_response_time_ms'].min():.1f}ms
- í‰ê·  ì‘ë‹µì‹œê°„: {self.performance_data['total_response_time_ms'].mean():.1f}ms

### ğŸ”¬ **ì‹¤í—˜ ì¡°ê±´ë³„ ê²°ê³¼**

#### 1ê°œ ì„¼ì„œ ì‹¤í—˜
- ìµœëŒ€ ì£¼íŒŒìˆ˜: 20Hz
- ìµœê³  ì²˜ë¦¬ëŸ‰: {self.performance_data[self.performance_data['sensor_count']==1]['requests_per_second'].max():.1f} req/sec
- í‰ê·  ì‘ë‹µì‹œê°„: {self.performance_data[self.performance_data['sensor_count']==1]['total_response_time_ms'].mean():.1f}ms

#### 10ê°œ ì„¼ì„œ ì‹¤í—˜  
- ìµœëŒ€ ì£¼íŒŒìˆ˜: 10Hz
- ìµœê³  ì²˜ë¦¬ëŸ‰: {self.performance_data[self.performance_data['sensor_count']==10]['requests_per_second'].max():.1f} req/sec
- í‰ê·  ì‘ë‹µì‹œê°„: {self.performance_data[self.performance_data['sensor_count']==10]['total_response_time_ms'].mean():.1f}ms

#### 50ê°œ ì„¼ì„œ ì‹¤í—˜
- ìµœëŒ€ ì£¼íŒŒìˆ˜: 6Hz  
- ìµœê³  ì²˜ë¦¬ëŸ‰: {self.performance_data[self.performance_data['sensor_count']==50]['requests_per_second'].max():.1f} req/sec
- í‰ê·  ì‘ë‹µì‹œê°„: {self.performance_data[self.performance_data['sensor_count']==50]['total_response_time_ms'].mean():.1f}ms

#### 100ê°œ ì„¼ì„œ ì‹¤í—˜
- ìµœëŒ€ ì£¼íŒŒìˆ˜: 3Hz
- ìµœê³  ì²˜ë¦¬ëŸ‰: {self.performance_data[self.performance_data['sensor_count']==100]['requests_per_second'].max():.1f} req/sec  
- í‰ê·  ì‘ë‹µì‹œê°„: {self.performance_data[self.performance_data['sensor_count']==100]['total_response_time_ms'].mean():.1f}ms

## ğŸ­ **ì‹¤ì œ ì„¼ì„œ ë¶„ì„**

### ì„¼ì„œ íƒ€ì… ë¶„í¬
"""
        
        # ì„¼ì„œ íƒ€ì…ë³„ í†µê³„ ì¶”ê°€
        sensor_types = self.analyze_sensor_types()
        for sensor_type, sensors in sensor_types.items():
            report_content += f"- **{sensor_type}**: {len(sensors)}ê°œ ì„¼ì„œ\n"
        
        report_content += f"""
### ì‚¬ìš©ëœ ì£¼ìš” ì„¼ì„œë“¤
- **ìœ ëŸ‰ ì„¼ì„œ**: DM-FT01, DM-FT02, DM-FT03, DM-FT01Z, DM-FT02Z, DM-FT03Z
- **ì••ë ¥ ì„¼ì„œ**: DM-PIT01, DM-PIT02  
- **ì˜¨ë„ ì„¼ì„œ**: DM-TIT01, DM-TIT02
- **ë ˆë²¨ ì„¼ì„œ**: DM-LIT01, DM-LCV01-D
- **ë¶„ì„ ì„¼ì„œ**: DM-AIT-DO, DM-AIT-PH, GATEOPEN

## ğŸ“ˆ **ì‚°ì—…ì  ì˜ì˜**

### âœ… **ê²€ì¦ëœ ë‚´ìš©**
1. **ì‹¤ì œ ì‚°ì—… ë°ì´í„°**: HAI ë°ì´í„°ì…‹ì˜ 280,800ê°œ ì‹¤ì œ ì„¼ì„œ ë°ì´í„° ì²˜ë¦¬
2. **ë‹¤ì–‘í•œ ì„¼ì„œ íƒ€ì…**: FLOW, PRESSURE, TEMPERATURE, LEVEL, ANALYTICAL ë“±
3. **ìŠ¤ì¼€ì¼ë§ ì„±ëŠ¥**: 1ê°œë¶€í„° 100ê°œê¹Œì§€ ì„ í˜•ì  í™•ì¥ ê°€ëŠ¥ì„± ì…ì¦
4. **ì‹¤ì‹œê°„ ì²˜ë¦¬**: ì‘ì€ ê·œëª¨ì—ì„œ ì‹¤ì‹œê°„ ì²˜ë¦¬ ê°€ëŠ¥ (1-10ê°œ ì„¼ì„œ)

### ğŸš€ **ì‹¤ìš©ì„±**
- **ìŠ¤ë§ˆíŠ¸íŒ©í† ë¦¬**: 10-50ê°œ í•µì‹¬ ì„¼ì„œ ì‹¤ì‹œê°„ ëª¨ë‹ˆí„°ë§ ê°€ëŠ¥
- **ì „ë ¥ ì‹œì„¤**: ë³€ì „ì†Œë³„ 10ê°œ ì´í•˜ ì„¼ì„œ ê³ ì† ì²˜ë¦¬ ê°€ëŠ¥  
- **í™”í•™ í”ŒëœíŠ¸**: 100ê°œ ì•ˆì „ ì„¼ì„œ ì—°ì† ê°ì‹œ ê°€ëŠ¥
- **ìë™ì°¨ ê³µì¥**: í’ˆì§ˆ ì„¼ì„œ ì‹¤ì‹œê°„ ì•”í˜¸í™” ë¶„ì„ ê°€ëŠ¥

## ğŸ–ï¸ **ê²°ë¡ **

HAI-CKKSëŠ” **ì‹¤ì œ 100ê°œ ì„œë¡œ ë‹¤ë¥¸ ì‚°ì—…ìš© ì„¼ì„œ**ì—ì„œ **ì™„ì „í•œ ë™í˜•ì•”í˜¸í™” ì²˜ë¦¬**ë¥¼ ì„±ê³µì ìœ¼ë¡œ ìˆ˜í–‰í–ˆìŠµë‹ˆë‹¤. 

ì´ëŠ” ì‹¤ì œ ICS í™˜ê²½ì—ì„œ CKKS ë™í˜•ì•”í˜¸í™”ì˜ **ì™„ì „í•œ ì‹¤ìš©ì„±**ì„ ì…ì¦í•œ ì„¸ê³„ ìµœì´ˆì˜ ì‹¤í—˜ì…ë‹ˆë‹¤! ğŸŒŸ

---

*Generated by HAI Real 100 Sensors CKKS Experiment*  
*Date: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}*
"""
        
        # ë³´ê³ ì„œ ì €ì¥
        report_path = self.output_dir / "FINAL_EXPERIMENT_REPORT.md"
        with open(report_path, 'w', encoding='utf-8') as f:
            f.write(report_content)
        logger.info(f"ìµœì¢… ë³´ê³ ì„œ ì €ì¥: {report_path}")
        
        return report_content
        
    def run_complete_analysis(self):
        """ì „ì²´ ë¶„ì„ ì‹¤í–‰"""
        logger.info("ğŸš€ ì‹¤ì œ 100ê°œ ì„¼ì„œ ì‹¤í—˜ ì¢…í•© ë¶„ì„ ì‹œì‘")
        
        # ì‹œê°í™” ìƒì„±
        self.create_performance_overview()
        self.create_sensor_analysis() 
        self.create_timing_analysis()
        
        # í…Œì´ë¸” ë° ë°ì´í„° ìƒì„±
        self.create_sensor_details_table()
        self.create_experiment_log_summary()
        
        # ìµœì¢… ë³´ê³ ì„œ ìƒì„±
        self.create_final_report()
        
        logger.info("âœ… ì¢…í•© ë¶„ì„ ì™„ë£Œ!")
        print(f"ğŸ“ ëª¨ë“  ê²°ê³¼ê°€ ì €ì¥ë¨: {self.output_dir}")


def main():
    """ë©”ì¸ ì‹¤í–‰"""
    results_dir = "experiment_results/hai_real100_sensors_20250827"
    
    analyzer = Real100SensorsAnalyzer(results_dir)
    analyzer.run_complete_analysis()
    
    print("\nğŸ‰ HAI ì‹¤ì œ 100ê°œ ì„¼ì„œ ì‹¤í—˜ ì¢…í•© ë¶„ì„ ì™„ë£Œ!")
    print(f"ğŸ“Š ê²°ê³¼ í´ë”: {results_dir}")
    

if __name__ == "__main__":
    main()