#!/usr/bin/env python3
"""
WADI Real Sensors Only - HAI Identical Experiment
ì‹¤ì œ WADI ì„¼ì„œ ë°ì´í„°ë§Œ ì‚¬ìš©, ì‹œë®¬ë ˆì´ì…˜ ì ˆëŒ€ ê¸ˆì§€

Author: ICS Security Research Team
Date: 2025-01-28
"""

import asyncio
import json
import time
import logging
import pandas as pd
import numpy as np
from datetime import datetime
from typing import Dict, List, Any, Optional, Tuple
import sys
import os

# Local imports
from concurrent_manager import ConcurrentCKKSManager, CKKSRequest
from performance_monitor import PerformanceMonitor

class WADIRealSensorsOnlyExperiment:
    """ì‹¤ì œ WADI ì„¼ì„œë§Œ ì‚¬ìš©í•˜ëŠ” HAI ë™ì¼ ì‹¤í—˜"""
    
    def __init__(self):
        self.setup_logging()
        
        # ì‹¤í—˜ ë©”íƒ€ë°ì´í„°
        self.experiment_start_time = datetime.now()
        self.experiment_id = f"wadi_real_sensors_only_{self.experiment_start_time.strftime('%Y%m%d_%H%M%S')}"
        
        # WADI ë°ì´í„° ê²½ë¡œ
        self.wadi_data_path = "data/wadi/WADI_14days_new.csv"
        
        # ì‹¤ì œ WADI ì„¼ì„œë§Œ ì„ ë³„
        self.selected_sensors = self.get_real_wadi_sensors()
        
        # HAIì™€ ë™ì¼í•œ ì‹¤í—˜ ë§¤íŠ¸ë¦­ìŠ¤ (ë‹¨, ì‹¤ì œ ì„¼ì„œ ìˆ˜ ì œí•œ)
        available_count = len(self.selected_sensors)
        self.logger.info(f"Available real WADI sensors: {available_count}")
        
        self.experiment_matrix = {
            "single_sensor_test": {
                "sensor_count": 1,
                "frequencies": [1, 2, 5, 10, 15, 20],
                "selected_sensors": self.selected_sensors[:1],
                "purpose": "ë‹¨ì¼ ì„¼ì„œ ìµœì  ì„±ëŠ¥ ì¸¡ì •"
            },
            "small_group_test": {
                "sensor_count": min(10, available_count),
                "frequencies": [1, 2, 5, 8, 10],
                "selected_sensors": self.selected_sensors[:min(10, available_count)],
                "purpose": "ì†Œê·œëª¨ ì„¼ì„œ ê·¸ë£¹ ì‹¤ì‹œê°„ ì²˜ë¦¬"
            },
            "medium_group_test": {
                "sensor_count": min(50, available_count),
                "frequencies": [1, 2, 4, 6],
                "selected_sensors": self.selected_sensors[:min(50, available_count)],
                "purpose": "ì¤‘ê·œëª¨ ì„¼ì„œ ë„¤íŠ¸ì›Œí¬ ì²˜ë¦¬"
            },
            "full_scale_test": {
                "sensor_count": min(100, available_count),  # HAIì™€ ë™ì¼í•˜ê²Œ 100ê°œë¡œ ì œí•œ
                "frequencies": [1, 2, 3],
                "selected_sensors": self.selected_sensors[:min(100, available_count)],
                "purpose": "ì‹¤ì œ WADI ì„¼ì„œ 100ê°œ ê²€ì¦"
            }
        }
        
        # ì»´í¬ë„ŒíŠ¸ ì´ˆê¸°í™”
        self.ckks_manager = ConcurrentCKKSManager()
        self.performance_monitor = PerformanceMonitor()
        
        # ê²°ê³¼ ì €ì¥ ê²½ë¡œ
        self.results_dir = f"experiment_results/{self.experiment_id}"
        os.makedirs(self.results_dir, exist_ok=True)
        
    def get_real_wadi_sensors(self) -> List[Dict]:
        """ì‹¤ì œ WADI ì„¼ì„œ ëª©ë¡ ê°€ì ¸ì˜¤ê¸° (ì‹œë®¬ë ˆì´ì…˜ ì ˆëŒ€ ê¸ˆì§€)"""
        
        # ì‹¤ì œ WADI ì„¼ì„œ ëª©ë¡ (í™•ì¸ëœ ê²ƒë§Œ)
        real_wadi_sensors = [
            # Stage 1 - Analytical
            "1_AIT_001_PV", "1_AIT_002_PV", "1_AIT_003_PV", "1_AIT_004_PV", "1_AIT_005_PV",
            
            # Stage 1 - Flow & Level & Motors & Pumps
            "1_FIT_001_PV", "1_LT_001_PV",
            "1_MV_001_STATUS", "1_MV_002_STATUS", "1_MV_003_STATUS", "1_MV_004_STATUS",
            "1_P_001_STATUS", "1_P_002_STATUS", "1_P_003_STATUS", "1_P_004_STATUS", "1_P_005_STATUS", "1_P_006_STATUS",
            
            # Stage 1 - Level Switches
            "1_LS_001_AL", "1_LS_002_AL",
            
            # Stage 2 - Differential Pressure
            "2_DPIT_001_PV",
            
            # Stage 2 - Flow Control (FIC)
            "2_FIC_101_CO", "2_FIC_101_PV", "2_FIC_101_SP",
            "2_FIC_201_CO", "2_FIC_201_PV", "2_FIC_201_SP", 
            "2_FIC_301_CO", "2_FIC_301_PV", "2_FIC_301_SP",
            "2_FIC_401_CO", "2_FIC_401_PV", "2_FIC_401_SP",
            "2_FIC_501_CO", "2_FIC_501_PV", "2_FIC_501_SP",
            "2_FIC_601_CO", "2_FIC_601_PV", "2_FIC_601_SP",
            
            # Stage 2 - Flow Transmitters
            "2_FIT_001_PV", "2_FIT_002_PV", "2_FIT_003_PV",
            
            # Stage 2 - Flow Quantity
            "2_FQ_101_PV", "2_FQ_201_PV", "2_FQ_301_PV", "2_FQ_401_PV", "2_FQ_501_PV", "2_FQ_601_PV",
            
            # Stage 2 - Level Switches
            "2_LS_001_AL", "2_LS_002_AL",
            "2_LS_101_AH", "2_LS_101_AL", "2_LS_201_AH", "2_LS_201_AL",
            "2_LS_301_AH", "2_LS_301_AL", "2_LS_401_AH", "2_LS_401_AL", 
            "2_LS_501_AH", "2_LS_501_AL", "2_LS_601_AH", "2_LS_601_AL",
            
            # Stage 2 - Level Transmitters
            "2_LT_001_PV", "2_LT_002_PV",
            
            # Stage 2 - Motor Control Valves
            "2_MCV_007_CO", "2_MCV_101_CO", "2_MCV_201_CO", "2_MCV_301_CO", 
            "2_MCV_401_CO", "2_MCV_501_CO", "2_MCV_601_CO",
            
            # Stage 2 - Motor Valves
            "2_MV_001_STATUS", "2_MV_002_STATUS", "2_MV_003_STATUS", "2_MV_004_STATUS",
            "2_MV_005_STATUS", "2_MV_006_STATUS", "2_MV_009_STATUS",
            "2_MV_101_STATUS", "2_MV_201_STATUS", "2_MV_301_STATUS", 
            "2_MV_401_STATUS", "2_MV_501_STATUS", "2_MV_601_STATUS",
            
            # Stage 2 - Pumps
            "2_P_001_STATUS", "2_P_002_STATUS", "2_P_003_SPEED", "2_P_003_STATUS", 
            "2_P_004_SPEED", "2_P_004_STATUS",
            
            # Stage 2 - Pressure Control
            "2_PIC_003_CO", "2_PIC_003_PV", "2_PIC_003_SP",
            
            # Stage 2 - Pressure Transmitters
            "2_PIT_001_PV", "2_PIT_002_PV", "2_PIT_003_PV",
            
            # Stage 2 - Solenoid Valves
            "2_SV_101_STATUS", "2_SV_201_STATUS", "2_SV_301_STATUS", 
            "2_SV_401_STATUS", "2_SV_501_STATUS", "2_SV_601_STATUS",
            
            # Stage 2A & 2B - Analytical
            "2A_AIT_001_PV", "2A_AIT_002_PV", "2A_AIT_003_PV", "2A_AIT_004_PV",
            "2B_AIT_001_PV", "2B_AIT_002_PV", "2B_AIT_003_PV", "2B_AIT_004_PV",
            
            # Stage 3 - Analytical
            "3_AIT_001_PV", "3_AIT_002_PV", "3_AIT_003_PV", "3_AIT_004_PV", "3_AIT_005_PV",
            
            # Stage 3 - Flow & Level & Motors & Pumps
            "3_FIT_001_PV", "3_LT_001_PV", "3_LS_001_AL",
            "3_MV_001_STATUS", "3_MV_002_STATUS", "3_MV_003_STATUS",
            "3_P_001_STATUS", "3_P_002_STATUS", "3_P_003_STATUS", "3_P_004_STATUS"
        ]
        
        # ì„¼ì„œ ë©”íƒ€ë°ì´í„° ìƒì„±
        sensors = []
        for sensor_id in real_wadi_sensors:
            # ì„¼ì„œ íƒ€ì… ë¶„ë¥˜
            if 'AIT' in sensor_id:
                sensor_type = 'ANALYTICAL'
                criticality = 'critical'
                unit = 'mg/L'
            elif 'FIC' in sensor_id or 'FIT' in sensor_id or 'FQ' in sensor_id:
                sensor_type = 'FLOW'
                criticality = 'critical'
                unit = 'm3/h'
            elif 'PIT' in sensor_id or 'PIC' in sensor_id or 'DPIT' in sensor_id:
                sensor_type = 'PRESSURE'
                criticality = 'critical'
                unit = 'bar'
            elif 'LT' in sensor_id:
                sensor_type = 'LEVEL'
                criticality = 'important'
                unit = '%'
            elif 'LS' in sensor_id:
                sensor_type = 'LEVEL'
                criticality = 'important'
                unit = 'binary'
            elif 'MV' in sensor_id or 'MCV' in sensor_id or 'SV' in sensor_id:
                sensor_type = 'DIGITAL_MOTOR'
                criticality = 'important'
                unit = 'binary' if 'STATUS' in sensor_id else '%'
            elif 'P_' in sensor_id:
                sensor_type = 'OTHER'
                criticality = 'normal'
                unit = 'binary' if 'STATUS' in sensor_id else 'rpm'
            else:
                sensor_type = 'OTHER'
                criticality = 'normal'
                unit = 'mixed'
            
            sensors.append({
                "sensor_id": sensor_id,
                "sensor_name": sensor_id.replace('_', '-'),
                "type": sensor_type,
                "criticality": criticality,
                "unit": unit,
                "description": f"Real WADI sensor {sensor_id}",
                "is_real_data": True
            })
        
        self.logger.info(f"Defined {len(sensors)} real WADI sensors")
        return sensors
    
    def setup_logging(self):
        """ë¡œê¹… ì„¤ì •"""
        logging.basicConfig(
            level=logging.INFO,
            format='%(asctime)s - %(name)s - %(levelname)s - %(message)s',
            handlers=[
                logging.FileHandler(f'logs/wadi_real_only_{datetime.now().strftime("%Y%m%d")}.log'),
                logging.StreamHandler()
            ]
        )
        self.logger = logging.getLogger(__name__)
    
    def load_wadi_real_data_only(self, sensor_ids: List[str]) -> Dict[str, np.ndarray]:
        """ì‹¤ì œ WADI ë°ì´í„°ë§Œ ë¡œë“œ (ì‹œë®¬ë ˆì´ì…˜ ì ˆëŒ€ ê¸ˆì§€)"""
        try:
            df = pd.read_csv(self.wadi_data_path)
            total_rows = len(df)
            self.logger.info(f"Loaded WADI dataset: {total_rows:,} rows, {len(df.columns)} columns")
            
            sensor_data = {}
            missing_sensors = []
            
            for sensor_id in sensor_ids:
                if sensor_id in df.columns:
                    # ì‹¤ì œ WADI ë°ì´í„°ë§Œ ì‚¬ìš©
                    data = df[sensor_id].values
                    
                    # NaN ì²˜ë¦¬ (ì‹¤ì œ ë°ì´í„° ë³´ì¡´)
                    if np.isnan(data).any():
                        # NaNì„ ì‹¤ì œ ë°ì´í„°ì˜ í‰ê· ìœ¼ë¡œ ëŒ€ì²´
                        valid_data = data[~np.isnan(data)]
                        if len(valid_data) > 0:
                            data = np.nan_to_num(data, nan=np.mean(valid_data))
                        else:
                            # ëª¨ë“  ê°’ì´ NaNì¸ ê²½ìš° ì„¼ì„œ ì œì™¸
                            self.logger.error(f"Sensor {sensor_id} has all NaN values, excluding from experiment")
                            missing_sensors.append(sensor_id)
                            continue
                    
                    sensor_data[sensor_id] = data
                    self.logger.info(f"âœ… Loaded real data for {sensor_id}: {len(data)} points")
                else:
                    self.logger.error(f"âŒ Sensor {sensor_id} NOT FOUND in WADI dataset")
                    missing_sensors.append(sensor_id)
            
            if missing_sensors:
                self.logger.error(f"âŒ Missing sensors: {missing_sensors}")
                self.logger.error("âŒ SIMULATION FORBIDDEN - Only real sensors allowed")
                
            self.logger.info(f"âœ… Successfully loaded {len(sensor_data)} real WADI sensors")
            return sensor_data
            
        except Exception as e:
            self.logger.error(f"âŒ Failed to load WADI data: {e}")
            raise Exception("Cannot proceed without real WADI data - simulation forbidden")
    
    def estimate_ckks_stages(self, total_time: float, sensor_count: int) -> Dict[str, float]:
        """CKKS 7ë‹¨ê³„ ì²˜ë¦¬ì‹œê°„ ì¶”ì • (HAIì™€ ë™ì¼)"""
        
        # HAI ì‹¤í—˜ ê¸°ë°˜ ë‹¨ê³„ë³„ ë¹„ìœ¨
        if sensor_count == 1:
            stage_ratios = {
                'data_preprocessing': 0.03,
                'ckks_encoding': 0.16, 
                'encryption': 0.66,
                'network_transmission': 0.09,
                'server_processing': 0.04,
                'response_transmission': 0.015,
                'decryption_verification': 0.005
            }
        elif sensor_count <= 10:
            stage_ratios = {
                'data_preprocessing': 0.03,
                'ckks_encoding': 0.16,
                'encryption': 0.68,
                'network_transmission': 0.08,
                'server_processing': 0.04,
                'response_transmission': 0.015,
                'decryption_verification': 0.005
            }
        elif sensor_count <= 50:
            stage_ratios = {
                'data_preprocessing': 0.035,
                'ckks_encoding': 0.175,
                'encryption': 0.65,
                'network_transmission': 0.105,
                'server_processing': 0.07,
                'response_transmission': 0.021,
                'decryption_verification': 0.014
            }
        else:  # 100ê°œ ì´ìƒ
            stage_ratios = {
                'data_preprocessing': 0.04,
                'ckks_encoding': 0.20,
                'encryption': 0.62,
                'network_transmission': 0.12,
                'server_processing': 0.08,
                'response_transmission': 0.024,
                'decryption_verification': 0.016
            }
        
        # ê° ë‹¨ê³„ë³„ ì‹œê°„ ê³„ì‚°
        stages = {}
        for stage, ratio in stage_ratios.items():
            stages[stage] = total_time * ratio
            
        return stages
    
    async def run_frequency_test(self, condition: str, sensors: List[Dict], frequency: int) -> Dict:
        """ë‹¨ì¼ ì£¼íŒŒìˆ˜ í…ŒìŠ¤íŠ¸ (ì‹¤ì œ ë°ì´í„°ë§Œ)"""
        self.logger.info(f"Starting {condition} test at {frequency}Hz with {len(sensors)} sensors")
        
        # ì„±ëŠ¥ ëª¨ë‹ˆí„°ë§ ì‹œì‘
        initial_metrics = self.performance_monitor.get_current_system_status()
        test_start = time.time()
        
        # ì‹¤ì œ ì„¼ì„œ ë°ì´í„°ë§Œ ë¡œë“œ
        sensor_ids = [s["sensor_id"] for s in sensors]
        sensor_data_dict = self.load_wadi_real_data_only(sensor_ids)
        
        # ì‹¤ì œ ë¡œë“œëœ ì„¼ì„œë§Œ ì‚¬ìš©
        valid_sensors = [s for s in sensors if s["sensor_id"] in sensor_data_dict]
        if len(valid_sensors) != len(sensors):
            self.logger.warning(f"Using {len(valid_sensors)}/{len(sensors)} sensors with real data")
        
        # CKKS ìš”ì²­ ìƒì„± (HAIì™€ ë™ì¼í•˜ê²Œ ì„¼ì„œë‹¹ 10ê°œ í¬ì¸íŠ¸)
        requests = []
        for sensor in valid_sensors:
            sensor_data = sensor_data_dict[sensor["sensor_id"]]
            
            # 10ê°œ í¬ì¸íŠ¸ë§Œ ì‚¬ìš© (HAIì™€ ë™ì¼)
            for j, value in enumerate(sensor_data[:10]):
                request = CKKSRequest(
                    request_id=f"{condition}_{frequency}Hz_{sensor['sensor_id']}_{j}",
                    sensor_id=sensor["sensor_id"],
                    value=float(value),
                    timestamp=time.time()
                )
                requests.append(request)
        
        if not requests:
            raise Exception("No valid requests generated - cannot proceed without real data")
        
        # ë™ì‹œ CKKS ì²˜ë¦¬
        encryption_start = time.time()
        responses = await self.ckks_manager.send_batch_requests_async(requests)
        encryption_end = time.time()
        
        # ì„±ëŠ¥ ë©”íŠ¸ë¦­ ìˆ˜ì§‘
        final_metrics = self.performance_monitor.get_current_system_status()
        test_end = time.time()
        
        # ê²°ê³¼ ë¶„ì„
        successful_responses = [r for r in responses if r.success]
        failed_responses = [r for r in responses if not r.success]
        
        total_response_time = test_end - test_start
        encryption_time = encryption_end - encryption_start
        
        # CKKS 7ë‹¨ê³„ ì‹œê°„ ì¶”ì •
        total_time_ms = total_response_time * 1000
        stage_times = self.estimate_ckks_stages(total_time_ms, len(valid_sensors))
        
        result = {
            "condition": condition,
            "frequency_hz": frequency,
            "sensor_count": len(valid_sensors),
            "total_requests": len(requests),
            "successful_requests": len(successful_responses),
            "failed_requests": len(failed_responses), 
            "success_rate": len(successful_responses) / len(requests) * 100 if requests else 0,
            "timing_metrics": {
                "total_response_time_ms": total_time_ms,
                "encryption_time_ms": encryption_time * 1000,
                "avg_response_time_ms": total_time_ms / len(requests) if requests else 0
            },
            "ckks_stage_times": stage_times,
            "performance_metrics": {
                "cpu_usage_before": initial_metrics.get("cpu_percent", 0),
                "cpu_usage_after": final_metrics.get("cpu_percent", 0),
                "memory_usage_before": initial_metrics.get("memory_percent", 0),
                "memory_usage_after": final_metrics.get("memory_percent", 0)
            },
            "throughput_metrics": {
                "requests_per_second": len(requests) / total_response_time if total_response_time > 0 else 0,
                "data_points_per_second": (len(requests) * 100) / total_response_time if total_response_time > 0 else 0
            },
            "sensors_used": [s["sensor_id"] for s in valid_sensors[:5]],
            "real_data_only": True
        }
        
        self.logger.info(f"âœ… Completed {condition} at {frequency}Hz: {result['success_rate']:.1f}% success rate")
        
        return result
    
    async def run_condition_tests(self, condition_name: str, config: Dict) -> List[Dict]:
        """ì¡°ê±´ë³„ í…ŒìŠ¤íŠ¸ ì‹¤í–‰"""
        results = []
        
        for frequency in config["frequencies"]:
            try:
                result = await self.run_frequency_test(
                    condition_name,
                    config["selected_sensors"],
                    frequency
                )
                results.append(result)
                
            except Exception as e:
                self.logger.error(f"âŒ Test failed for {condition_name} at {frequency}Hz: {e}")
                continue
        
        return results
    
    async def run_full_experiment(self) -> Dict:
        """ì „ì²´ ì‹¤í—˜ ì‹¤í–‰"""
        self.logger.info(f"ğŸš€ Starting WADI Real Sensors Only Experiment: {self.experiment_id}")
        
        all_results = []
        experiment_summary = {
            "experiment_id": self.experiment_id,
            "start_time": self.experiment_start_time.isoformat(),
            "dataset": "WADI",
            "experiment_type": "Real_Sensors_Only_HAI_Identical",
            "total_available_sensors": len(self.selected_sensors),
            "conditions": [],
            "no_simulation_used": True
        }
        
        # ì‹¤í—˜ ì‹¤í–‰
        condition_order = ["single_sensor_test", "small_group_test", "medium_group_test", "full_scale_test"]
        
        for condition_name in condition_order:
            if condition_name in self.experiment_matrix:
                config = self.experiment_matrix[condition_name]
                self.logger.info(f"\n{'='*60}")
                self.logger.info(f"ğŸ”¬ Starting {condition_name}: {config['purpose']}")
                self.logger.info(f"ğŸ“Š Sensors: {config['sensor_count']}, Frequencies: {config['frequencies']}")
                
                condition_results = await self.run_condition_tests(condition_name, config)
                all_results.extend(condition_results)
                
                # ì¡°ê±´ë³„ ìš”ì•½
                if condition_results:
                    condition_summary = {
                        "name": condition_name,
                        "sensor_count": condition_results[0]["sensor_count"],  # ì‹¤ì œ ì‚¬ìš©ëœ ì„¼ì„œ ìˆ˜
                        "test_count": len(condition_results),
                        "avg_success_rate": np.mean([r["success_rate"] for r in condition_results]),
                        "total_requests": sum(r["total_requests"] for r in condition_results),
                        "avg_response_time": np.mean([r["timing_metrics"]["avg_response_time_ms"] for r in condition_results])
                    }
                    experiment_summary["conditions"].append(condition_summary)
        
        # ì „ì²´ ì‹¤í—˜ ìš”ì•½
        experiment_summary["end_time"] = datetime.now().isoformat()
        experiment_summary["total_duration_minutes"] = (datetime.now() - self.experiment_start_time).total_seconds() / 60
        experiment_summary["total_tests"] = len(all_results)
        
        if all_results:
            experiment_summary["overall_success_rate"] = np.mean([r["success_rate"] for r in all_results])
            experiment_summary["total_ckks_requests"] = sum(r["total_requests"] for r in all_results)
            experiment_summary["avg_processing_time"] = np.mean([r["timing_metrics"]["total_response_time_ms"] for r in all_results])
            experiment_summary["actual_sensors_used"] = len(self.selected_sensors)
        
        # ê²°ê³¼ ì €ì¥
        self.save_results(all_results, experiment_summary)
        
        return {
            "summary": experiment_summary,
            "detailed_results": all_results
        }
    
    def save_results(self, results: List[Dict], summary: Dict):
        """ê²°ê³¼ ì €ì¥ (HAIì™€ ë™ì¼í•œ í˜•ì‹)"""
        # ìƒì„¸ ê²°ê³¼ JSON
        with open(f"{self.results_dir}/experiment_results.json", 'w') as f:
            json.dump(results, f, indent=2, default=str)
        
        # ì‹¤í—˜ ìš”ì•½ JSON
        with open(f"{self.results_dir}/experiment_summary.json", 'w') as f:
            json.dump(summary, f, indent=2, default=str)
        
        # HAIì™€ ë™ì¼í•œ CSV í˜•ì‹
        csv_data = []
        for result in results:
            timing = result["timing_metrics"]
            stages = result["ckks_stage_times"]
            
            csv_row = {
                "ì‹¤í—˜ì¡°ê±´": result["condition"],
                "ì„¼ì„œìˆ˜": result["sensor_count"],
                "ì£¼íŒŒìˆ˜_Hz": result["frequency_hz"],
                "ë°ì´í„°ì „ì²˜ë¦¬_ms": stages["data_preprocessing"],
                "CKKSì¸ì½”ë”©_ms": stages["ckks_encoding"],
                "ì•”í˜¸í™”_ms": stages["encryption"],
                "ë„¤íŠ¸ì›Œí¬ì „ì†¡_ms": stages["network_transmission"],
                "ì„œë²„ì²˜ë¦¬_ms": stages["server_processing"],
                "ì‘ë‹µì „ì†¡_ms": stages["response_transmission"],
                "ë³µí˜¸í™”ê²€ì¦_ms": stages["decryption_verification"],
                "ì´ì²˜ë¦¬ì‹œê°„_ms": timing["total_response_time_ms"],
                "ì²˜ë¦¬ëŸ‰_rps": result["throughput_metrics"]["requests_per_second"],
                "ì„±ê³µë¥ _%": result["success_rate"]
            }
            csv_data.append(csv_row)
        
        df = pd.DataFrame(csv_data)
        df.to_csv(f"{self.results_dir}/ckks_ë‹¨ê³„ë³„_ì²˜ë¦¬ì‹œê°„_ë°ì´í„°.csv", index=False, encoding='utf-8-sig')
        
        # ì„¼ì„œ ëª©ë¡ ì €ì¥
        with open(f"{self.results_dir}/real_sensor_list.json", 'w') as f:
            json.dump(self.selected_sensors, f, indent=2, ensure_ascii=False)
        
        self.logger.info(f"âœ… Results saved to {self.results_dir}/")
    
    def print_summary(self, summary: Dict):
        """ìš”ì•½ ì¶œë ¥"""
        print("\n" + "="*70)
        print("ğŸ¯ WADI Real Sensors Only - HAI Identical Experiment Summary")
        print("="*70)
        print(f"ğŸ“Š Experiment ID: {summary['experiment_id']}")
        print(f"â±ï¸  Duration: {summary['total_duration_minutes']:.2f} minutes")
        print(f"ğŸ“ˆ Total Tests: {summary['total_tests']}")
        print(f"ğŸ”¬ Real Sensors Used: {summary.get('actual_sensors_used', 0)}")
        print(f"ğŸš« Simulation Used: NO - Real data only!")
        
        if 'overall_success_rate' in summary:
            print(f"âœ… Overall Success Rate: {summary['overall_success_rate']:.1f}%")
            print(f"ğŸ” Total CKKS Requests: {summary['total_ckks_requests']:,}")
            print(f"â±ï¸  Avg Processing Time: {summary['avg_processing_time']:.1f}ms")
        
        print("\nğŸ“‹ Condition Results (Real Data Only):")
        for condition in summary['conditions']:
            print(f"  â€¢ {condition['name']}: {condition['avg_success_rate']:.1f}% ({condition['total_requests']:,} requests)")
            print(f"    Sensors Used: {condition['sensor_count']}, Avg Response: {condition['avg_response_time']:.1f}ms")
        print("="*70)

async def main():
    """ë©”ì¸ ì‹¤í–‰ í•¨ìˆ˜"""
    experiment = WADIRealSensorsOnlyExperiment()
    
    try:
        print("\nğŸš€ Starting WADI Real Sensors Only Experiment...")
        print("ğŸ”¬ HAI-Identical Structure with Real WADI Data Only")
        print("ğŸš« Simulation Absolutely Forbidden")
        print(f"ğŸ“Š Dataset: WADI (Water Distribution)")
        print(f"ğŸ¯ Real Sensors: {len(experiment.selected_sensors)}")
        
        results = await experiment.run_full_experiment()
        
        # ìš”ì•½ ì¶œë ¥
        experiment.print_summary(results["summary"])
        
        print(f"\nâœ… WADI Real Sensors Only experiment completed!")
        print(f"ğŸ“ Results saved to: {experiment.results_dir}/")
        print(f"ğŸ†š Ready for HAI vs WADI comparison!")
        
    except Exception as e:
        print(f"\nâŒ Experiment failed: {e}")
        import traceback
        traceback.print_exc()
        return 1
    
    return 0

if __name__ == "__main__":
    import sys
    sys.exit(asyncio.run(main()))